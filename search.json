[
  {
    "objectID": "package_distribution-revealjs.html#my-motivations-on-this-topic",
    "href": "package_distribution-revealjs.html#my-motivations-on-this-topic",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "My motivations on this topic",
    "text": "My motivations on this topic\n\nResearch scientist in high energy physics and data science at University of Wisconsin-Madison Data Science Institute\nAnalysis Systems area lead for IRIS-HEP\nMember of ATLAS collaboration\nAdministrator of Scikit-HEP community organization\nCommunity member of the Scientific Python project\nCare about reusable open science to be able to push physics forward at the community scale"
  },
  {
    "objectID": "package_distribution-revealjs.html#knowledgeable-colleagues",
    "href": "package_distribution-revealjs.html#knowledgeable-colleagues",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Knowledgeable colleagues",
    "text": "Knowledgeable colleagues\n\n\n\nHenry Schreiner\nPrinceton University, IRIS-HEP, PyPA, Scikit-Build\n\n\nAngus Hollands\n2i2c, The Executable Books Project, MyST"
  },
  {
    "objectID": "package_distribution-revealjs.html#hypothetical-workflow-for-the-typical-scientist",
    "href": "package_distribution-revealjs.html#hypothetical-workflow-for-the-typical-scientist",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Hypothetical workflow for the typical scientist",
    "text": "Hypothetical workflow for the typical scientist\n\nWork on idea for paper with collaborators\nDo exploratory analysis in scripts and Jupyter ecosystem\nAs research progresses need to write more complicated functions and workflows\nCode begins to sprawl across multiple directories\nSoftware dependencies begin to become more complicated\nThe code “works on my machine”, but what about your collaborators?\n\n\nPeople heroically press forward, but this is painful, and not reusable"
  },
  {
    "objectID": "package_distribution-revealjs.html#reusable-science-step-by-step",
    "href": "package_distribution-revealjs.html#reusable-science-step-by-step",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Reusable science, step by step",
    "text": "Reusable science, step by step\nIn this first scenario, you will probably see a lot of sys.path manipulation and utils.py\n$ tree examples/edit_sys_path\nexamples/edit_sys_path\n├── code\n│   └── utils.py  # helper functions rosen, rosen_der\n├── example.py  # want to import rosen, rosen_der\n└── jupytext.toml\n\n1 directory, 3 files"
  },
  {
    "objectID": "package_distribution-revealjs.html#section",
    "href": "package_distribution-revealjs.html#section",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "# example.py\nimport sys\nfrom pathlib import Path\n# Make ./code/utils.py visible to sys.path\n# sys.path[1] should be after cwd and before virtual environment\nsys.path.insert(1, str(Path(__file__).parent / \"code\"))\nfrom utils import rosen, rosen_der\nx0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\nresult = minimize(rosen, x0, method=\"BFGS\",\n                  jac=rosen_der, options={\"disp\": True})\noptimized_params = result.x\n# array([1.00000004, 1.0000001 , 1.00000021, 1.00000044, 1.00000092])"
  },
  {
    "objectID": "package_distribution-revealjs.html#next-steps-packaging-your-code",
    "href": "package_distribution-revealjs.html#next-steps-packaging-your-code",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Next steps: Packaging your code",
    "text": "Next steps: Packaging your code\n\nReal emphasis is just that your code is now installable\n\nAnywhere your Python virtual environment is active you can use your code\n\nSo following The Zen of Python this should be very straightforward?\n\n\n$ python -c 'import this' | grep obvious\nThere should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch."
  },
  {
    "objectID": "package_distribution-revealjs.html#section-1",
    "href": "package_distribution-revealjs.html#section-1",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Maybe not so much. :(\n\nYou might be asking: Why is there more than one thing?"
  },
  {
    "objectID": "package_distribution-revealjs.html#simple-packaging-example",
    "href": "package_distribution-revealjs.html#simple-packaging-example",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Simple packaging example",
    "text": "Simple packaging example\nModern PEP 518 compliant build backends just need a single file: pyproject.toml\n$ tree examples/simple_packaging\nexamples/simple_packaging\n\n├── LICENSE\n├── pyproject.toml  # controls packaging and interactions with tools\n├── README.md\n├── src\n│   └── rosen\n│       ├── example.py\n│       ├── __init__.py\n│       └── _version.py\n└── tests\n    └── test_example.py\n\n3 directories, 7 files"
  },
  {
    "objectID": "package_distribution-revealjs.html#simple-packaging-example-pyproject.toml",
    "href": "package_distribution-revealjs.html#simple-packaging-example-pyproject.toml",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Simple packaging example: pyproject.toml",
    "text": "Simple packaging example: pyproject.toml\nWhat is .toml?\n“TOML aims to be a minimal configuration file format that’s easy to read due to obvious semantics. TOML is designed to map unambiguously to a hash table. TOML should be easy to parse into data structures in a wide variety of languages.” — https://toml.io/ (emphasis mine)\nIn recent years TOML has seen a rise in popularity for configuration files and lock files. Things that need to be easy to read (humans) and easy to parse (machines)."
  },
  {
    "objectID": "package_distribution-revealjs.html#section-2",
    "href": "package_distribution-revealjs.html#section-2",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Defining how your project should get built\n[build-system]\nrequires = [\n    \"hatchling&gt;=1.13.0\",\n    \"hatch-vcs&gt;=0.3.0\",\n]\nbuild-backend = \"hatchling.build\"\n..."
  },
  {
    "objectID": "package_distribution-revealjs.html#simple-packaging-example-installing-your-code",
    "href": "package_distribution-revealjs.html#simple-packaging-example-installing-your-code",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Simple packaging example: Installing your code",
    "text": "Simple packaging example: Installing your code\nYou can now locally install your package into your Python virtual environment\n$ cd examples/simple_packaging\n$ python -m pip install --upgrade pip wheel\n$ python -m pip install .\nSuccessfully built rosen\nInstalling collected packages: rosen\nSuccessfully installed rosen-0.0.1\n$ python -m pip show rosen\nName: rosen\nVersion: 0.0.1\nSummary: Example package for demonstration\nHome-page:\nAuthor:\nAuthor-email: Matthew Feickert &lt;matthew.feickert@cern.ch&gt;\nLicense: MIT\nLocation: ***/lib/python3.12/site-packages\nRequires: numpy, scipy\nRequired-by:"
  },
  {
    "objectID": "package_distribution-revealjs.html#packaging-doesnt-slow-down-development",
    "href": "package_distribution-revealjs.html#packaging-doesnt-slow-down-development",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Packaging doesn’t slow down development",
    "text": "Packaging doesn’t slow down development\nPEP 518 compliant build backends allow for “editable installs”\n$ python -m pip install --upgrade --editable .\n$ python -m pip show rosen | grep --ignore-case 'location'\nLocation: ***/lib/python3.12/site-packages\nEditable project location: ***/examples/simple_packaging\nEditable installs add the files in the development directory to Python’s import path. (Only need to re-installation if you change the project metadata.)\nCan develop your code under src/ and have immediate access to it"
  },
  {
    "objectID": "package_distribution-revealjs.html#packaging-compiled-extensions",
    "href": "package_distribution-revealjs.html#packaging-compiled-extensions",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Packaging compiled extensions",
    "text": "Packaging compiled extensions\nWith modern packaging infrastructure, packaging compiled extensions requires small extra work\n$ tree examples/compiled_packaging\n\nexamples/compiled_packaging\n├── CMakeLists.txt  # Addition of CMake\n├── LICENSE\n├── pyproject.toml  # build backend change\n├── README.md\n├── src\n│   ├── basic_math.cpp  # C++ extension\n│   └── rosen_cpp\n│       ├── example.py\n│       └── __init__.py\n└── tests\n    └── test_example.py\n\n3 directories, 8 files"
  },
  {
    "objectID": "package_distribution-revealjs.html#section-3",
    "href": "package_distribution-revealjs.html#section-3",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "pyproject.toml:\nSwap build system to scikit-build-core + pybind11\n[build-system]\nrequires = [\n  \"scikit-build-core\",\n  \"pybind11\"\n  ]\nbuild-backend = \"scikit_build_core.build\"\n..."
  },
  {
    "objectID": "package_distribution-revealjs.html#section-4",
    "href": "package_distribution-revealjs.html#section-4",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "CMakeLists.txt:\n# Specify CMake version and project language\ncmake_minimum_required(VERSION 3.15...3.30)\nproject(${SKBUILD_PROJECT_NAME} LANGUAGES CXX)\n# Setup pybind11\nset(PYBIND11_FINDPYTHON ON)\nfind_package(pybind11 CONFIG REQUIRED)\n# Add the pybind11 module to build targets\npybind11_add_module(basic_math MODULE src/basic_math.cpp)\ninstall(TARGETS basic_math DESTINATION ${SKBUILD_PROJECT_NAME})"
  },
  {
    "objectID": "package_distribution-revealjs.html#section-5",
    "href": "package_distribution-revealjs.html#section-5",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "src/basic_math.cpp:\n#include &lt;pybind11/pybind11.h&gt;\nint add(int i, int j) { return i + j; }\nnamespace py = pybind11;\nPYBIND11_MODULE(basic_math, m) {\n  m.def(\"add\", &add, R\"pbdoc(\n      Add two numbers\n  )pbdoc\");\n...\n}"
  },
  {
    "objectID": "package_distribution-revealjs.html#packaging-compiled-extensions-installing",
    "href": "package_distribution-revealjs.html#packaging-compiled-extensions-installing",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Packaging compiled extensions: Installing",
    "text": "Packaging compiled extensions: Installing\nInstalling locally is the same as for the pure-Python example:\n$ cd examples/simple_packaging\n$ python -m pip install --upgrade pip wheel\n$ python -m pip install .\nSuccessfully built rosen-cpp\nInstalling collected packages: rosen-cpp\nSuccessfully installed rosen-cpp-0.0.1\nModule name is that given in C++:\nfrom rosen_cpp import basic_math\nbasic_math.add(1, 2)\n# 3"
  },
  {
    "objectID": "package_distribution-revealjs.html#going-further-distributing-packages",
    "href": "package_distribution-revealjs.html#going-further-distributing-packages",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Going further: Distributing packages",
    "text": "Going further: Distributing packages\nIf your code is publicly available on the WWW in a Git repository, you’ve already done a version of distribution!\n# General pattern is:\n# python -m pip install \"project @ git+https://example.com/repo/project.git@branch#subdirectory=path\"\n$ python -m pip install \\\n  \"git+https://github.com/matthewfeickert-talks/talk-urssi-summer-school-2024.git#subdirectory=examples/simple_packaging\"\n(more reasonable font size, and more common, example)\n# Works for pure-Python packages\n$ python -m pip install --upgrade \"git+https://github.com/scikit-hep/pyhf.git\"\n# as well as packages with compiled extensions\n$ python -m pip install --upgrade \"git+https://github.com/scikit-hep/iminuit.git\""
  },
  {
    "objectID": "package_distribution-revealjs.html#section-6",
    "href": "package_distribution-revealjs.html#section-6",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Can now securely upload the distributions under ./dist/ to any package index that understands how to use them.\nThe most common is the Python Package Index (PyPI) which serves as the default package index for pip."
  },
  {
    "objectID": "package_distribution-revealjs.html#distributing-packages-conda-forge",
    "href": "package_distribution-revealjs.html#distributing-packages-conda-forge",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Distributing packages: conda-forge",
    "text": "Distributing packages: conda-forge\nThe conda family of package managers (conda, mamba, micromamba, pixi) take an alternative approach from pip.\nInstead of installing Python packages, they act as general purpose package managers and install all dependencies (including Python) as OS and architecture specific built binaries (.conda files — zipfile containing compressed tar files) hosted on conda-forge.\nAllows an additional level of runtime environment specification not possible with just pip, though getting environment solves right can become more complicated."
  },
  {
    "objectID": "package_distribution-revealjs.html#defining-the-environment-application-vs.-library",
    "href": "package_distribution-revealjs.html#defining-the-environment-application-vs.-library",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Defining the environment: Application vs. Library",
    "text": "Defining the environment: Application vs. Library\nHave been reasonably assuming that packaged code can be used in arbitrary environments with other code that is compatible (library-like).\nFor distributing code, this is probably the correct view, but your analysis is not a library. Your analysis is an application (a hand crafted implementation of code from libraries).\nWhile your analysis might run with arbitrary configurations of the defined libraries and runtimes (reusable) want to also have a hash-level specified version for reproduciblity: a lock file"
  },
  {
    "objectID": "package_distribution-revealjs.html#defining-the-environment-lock-file",
    "href": "package_distribution-revealjs.html#defining-the-environment-lock-file",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Defining the environment: Lock file",
    "text": "Defining the environment: Lock file\nLock files are simple: A hash level record of every dependency in the environment.\nAllow for reproducibility by simply being an list of every file to download from the internet.\nShould be programmatically generated from a high level requirements file and maintained in version control with your analysis.\n\nFor pip: pip-tools, pdm, pipenv, poetry\nFor conda family: conda-lock, pixi"
  },
  {
    "objectID": "package_distribution-revealjs.html#defining-the-environment-comparing-to-julia",
    "href": "package_distribution-revealjs.html#defining-the-environment-comparing-to-julia",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Defining the environment: Comparing to Julia",
    "text": "Defining the environment: Comparing to Julia\nThe approach of pixi is similar to Julia.\n\nProject.toml: describes the project on a high level\nManifest.toml: absolute record of the state of the packages in the environment (a lock file)\n\n\nJulia’s package manager Pkg.jl provides users a high level interface to edit Project.toml and then automatically updates Manifest.toml in response. Reproducibility of environment by default!\n\n\nLibrary: Project.toml in version control\nApplication: Project.toml and Manifest.toml in version control"
  },
  {
    "objectID": "package_distribution-revealjs.html#areas-still-to-discuss-another-time",
    "href": "package_distribution-revealjs.html#areas-still-to-discuss-another-time",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Areas still to discuss another time",
    "text": "Areas still to discuss another time\n\nFull environment specification with Linux (Open Container Initiative (OCI)) container images (Docker, Apptainer, Podman)\nOrchestration of multiple environments inside of an analysis\n\nUsing workflow languages\n\nThe difficult realities of long term preservation\n\nAssumptions of present technologies don’t translate forever into the future, infrastructure goes away\nHow to store files that aren’t “code” (e.g. images, training data, database files) — c.f. Zenodo\n\nWhat analysis reuse looks like\n\nRECAST(particle physics)"
  },
  {
    "objectID": "package_distribution-revealjs.html#recommendations-tooling",
    "href": "package_distribution-revealjs.html#recommendations-tooling",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Recommendations: Tooling",
    "text": "Recommendations: Tooling\nDon’t start your next Python project from scratch! Use the Scientific Python library development Cookiecutter: cookie\n$ pipx install cookiecutter\n$ cookiecutter gh:scientific-python/cookie\n#  [1/14] The name of your project (package):\n# ...\ncookie will setup your repository for you with templated layouts for 11 different build backends and adheres to packaging and development best practices."
  },
  {
    "objectID": "package_distribution-revealjs.html#recommendations-community-guides",
    "href": "package_distribution-revealjs.html#recommendations-community-guides",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Recommendations: Community Guides",
    "text": "Recommendations: Community Guides\nPackaging standards and best practices continue to change and get better. Instead of trying to maintain your own resources follow and engage with community resources created by the teams that are building the tools and infrastructure.\n\nScientific Python Library Development Guide"
  },
  {
    "objectID": "package_distribution-revealjs.html#recommendations-collaboration",
    "href": "package_distribution-revealjs.html#recommendations-collaboration",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Recommendations: Collaboration",
    "text": "Recommendations: Collaboration\nFind and start working with Research Software Engineers (RSE).\n\nI don’t think that most scientists care/get excited about learning packaging tools. We just want things to work. RSEs can make that easier and are SUPER knowledgeable!\n\nI’m among the “not excited”. I care about packaging because I care about reusable tools for science.\n\n\n\n\n\n\nSociety of Research Software Engineering"
  },
  {
    "objectID": "package_distribution-revealjs.html#recommendations-zenodo",
    "href": "package_distribution-revealjs.html#recommendations-zenodo",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Recommendations: Zenodo",
    "text": "Recommendations: Zenodo\nVersioned archive of everything: code, documents, data products, data sets\n\n\n\n\n\nDOI for project and each version"
  },
  {
    "objectID": "package_distribution-revealjs.html#summary",
    "href": "package_distribution-revealjs.html#summary",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "Summary",
    "text": "Summary\n\nWhirlwind tour of lifting analysis code from version control, to packages, distributed binaries, and the rest of the world\nNot a hopeless bog of technical debt, but community infrastructure built by people who you can collaborate with\nReusable code can be a nucleation point for communities"
  },
  {
    "objectID": "package_distribution-revealjs.html#references",
    "href": "package_distribution-revealjs.html#references",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "References",
    "text": "References\n\nLevel Up Your Python, Henry Schreiner\nPython Packaging User Guide, Packaging Python Projects Tutorial, The PyPA\nScientific Python Library Development Guide, Scientific Python (originally made by Scikit-HEP)\ncookie, Scientific Python (originally made by Scikit-HEP)\nINTERSECT’s packaging tutorial, INTERSECT"
  },
  {
    "objectID": "package_distribution.html",
    "href": "package_distribution.html",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Work on idea for paper with collaborators\nDo exploratory analysis in scripts and Jupyter ecosystem\nAs research progresses need to write more complicated functions and workflows\nCode begins to sprawl across multiple directories\nSoftware dependencies begin to become more complicated\nThe code “works on my machine”, but what about your collaborators?\n\n\nPeople heroically press forward, but this is painful, and not reusable\n\n\n\n\nIn this first scenario, you will probably see a lot of sys.path manipulation and utils.py\n$ tree examples/edit_sys_path\nexamples/edit_sys_path\n├── code\n│   └── utils.py  # helper functions rosen, rosen_der\n├── example.py  # want to import rosen, rosen_der\n└── jupytext.toml\n\n1 directory, 3 files\n\n\n\n# example.py\nimport sys\nfrom pathlib import Path\n# Make ./code/utils.py visible to sys.path\n# sys.path[1] should be after cwd and before virtual environment\nsys.path.insert(1, str(Path(__file__).parent / \"code\"))\nfrom utils import rosen, rosen_der\nx0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\nresult = minimize(rosen, x0, method=\"BFGS\",\n                  jac=rosen_der, options={\"disp\": True})\noptimized_params = result.x\n# array([1.00000004, 1.0000001 , 1.00000021, 1.00000044, 1.00000092])\n\n\nThis is already better than having everything in a single massive file\nHowever, now things are tied to this relative path on your computer\n\n# Make ./code/utils.py visible to sys.path\nsys.path.insert(1, str(Path(__file__).parent / \"code\"))\nfrom utils import rosen, rosen_der\n\nand are brittle to refactoring and change\n\nBut we can do much better!\n\n\n\n\n\n\nReal emphasis is just that your code is now installable\n\nAnywhere your Python virtual environment is active you can use your code\n\nSo following The Zen of Python this should be very straightforward?\n\n\n$ python -c 'import this' | grep obvious\nThere should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch.\n\n\n\n\nMaybe not so much. :(\n\n\n\n\n\n\nYou might be asking: Why is there more than one thing?\n\nThe good news: Python packaging has improved dramatically in the last 5 years\n- It has never been easier to just point your package manager to some code locally, or on the internet, and get working Python code installed and running on your machine regardless of operating system or architecture\n\n- This is a small miracle\nThe bad news: Python packaging has expanded dramatically in the last 5 years\n- By creating standards the PyPA allowed for an ecosystem of packaging backends to be created to tackle various problems (this is good!)\n\n- This means that our The Zen of Python expectations are violated and we need to make design choices (hard for beginners)\n\nThe okay news: You can probably default to the simplest thing\npure Python: Probably hatch compiled extensions: Probably setuptools + pybind11 or scikit-build-core + pybind11\n\n\n\n\n\nPython Packaging User Guide, Packaging Python Projects Tutorial\n\n\n\n\n\n\nScientific Python Library Development Guide\n\n\n\n\n\n\n\nModern PEP 518 compliant build backends just need a single file: pyproject.toml\n$ tree examples/simple_packaging\nexamples/simple_packaging\n\n├── LICENSE\n├── pyproject.toml  # controls packaging and interactions with tools\n├── README.md\n├── src\n│   └── rosen\n│       ├── example.py\n│       ├── __init__.py\n│       └── _version.py\n└── tests\n    └── test_example.py\n\n3 directories, 7 files\n\n\n\nWhat is .toml?\n“TOML aims to be a minimal configuration file format that’s easy to read due to obvious semantics. TOML is designed to map unambiguously to a hash table. TOML should be easy to parse into data structures in a wide variety of languages.” — https://toml.io/ (emphasis mine)\nIn recent years TOML has seen a rise in popularity for configuration files and lock files. Things that need to be easy to read (humans) and easy to parse (machines).\n\n\n\nDefining how your project should get built\n[build-system]\nrequires = [\n    \"hatchling&gt;=1.13.0\",\n    \"hatch-vcs&gt;=0.3.0\",\n]\nbuild-backend = \"hatchling.build\"\n...\n\nDefining project metadata and requirements\n[project]\nname = \"rosen\"\ndynamic = [\"version\"]\ndescription = \"Example package for demonstration\"\nreadme = \"README.md\"\nlicense = { text = \"MIT\" }  # SPDX short identifier\nauthors = [\n  { name = \"Matthew Feickert\", email = \"matthew.feickert@cern.ch\" },\n]\nrequires-python = \"&gt;=3.8\"\ndependencies = [\n    \"scipy&gt;=1.6.0\",\n    \"numpy\",  # compatible versions controlled through scipy\n]\n...\n\nConfiguring tooling options and interactions with other tools\n[tool.hatch.version]\nsource = \"vcs\"\n[tool.hatch.version.raw-options]\nlocal_scheme = \"no-local-version\"\n# Need to give root as we aren't at the same level as the git repo\nroot = \"../..\"\n[tool.hatch.build.hooks.vcs]\nversion-file = \"src/rosen/_version.py\"\n...\n\n\n\nYou can now locally install your package into your Python virtual environment\n$ cd examples/simple_packaging\n$ python -m pip install --upgrade pip wheel\n$ python -m pip install .\nSuccessfully built rosen\nInstalling collected packages: rosen\nSuccessfully installed rosen-0.0.1\n$ python -m pip show rosen\nName: rosen\nVersion: 0.0.1\nSummary: Example package for demonstration\nHome-page:\nAuthor:\nAuthor-email: Matthew Feickert &lt;matthew.feickert@cern.ch&gt;\nLicense: MIT\nLocation: ***/lib/python3.12/site-packages\nRequires: numpy, scipy\nRequired-by:\n\nand use it anywhere\n# example.py\nimport numpy as np\nfrom scipy.optimize import minimize\n# We can now import our code\nfrom rosen.example import rosen, rosen_der\nx0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\nresult = minimize(rosen, x0, method=\"BFGS\",\n                  jac=rosen_der, options={\"disp\": True})\noptimized_params = result.x\n# array([1.00000004, 1.0000001 , 1.00000021, 1.00000044, 1.00000092])\n\n\n\nPEP 518 compliant build backends allow for “editable installs”\n$ python -m pip install --upgrade --editable .\n$ python -m pip show rosen | grep --ignore-case 'location'\nLocation: ***/lib/python3.12/site-packages\nEditable project location: ***/examples/simple_packaging\nEditable installs add the files in the development directory to Python’s import path. (Only need to re-installation if you change the project metadata.)\nCan develop your code under src/ and have immediate access to it\n\n\n\nWith modern packaging infrastructure, packaging compiled extensions requires small extra work\n$ tree examples/compiled_packaging\n\nexamples/compiled_packaging\n├── CMakeLists.txt  # Addition of CMake\n├── LICENSE\n├── pyproject.toml  # build backend change\n├── README.md\n├── src\n│   ├── basic_math.cpp  # C++ extension\n│   └── rosen_cpp\n│       ├── example.py\n│       └── __init__.py\n└── tests\n    └── test_example.py\n\n3 directories, 8 files\n\n\n\npyproject.toml:\nSwap build system to scikit-build-core + pybind11\n[build-system]\nrequires = [\n  \"scikit-build-core\",\n  \"pybind11\"\n  ]\nbuild-backend = \"scikit_build_core.build\"\n...\n\n\n\nCMakeLists.txt:\n# Specify CMake version and project language\ncmake_minimum_required(VERSION 3.15...3.30)\nproject(${SKBUILD_PROJECT_NAME} LANGUAGES CXX)\n# Setup pybind11\nset(PYBIND11_FINDPYTHON ON)\nfind_package(pybind11 CONFIG REQUIRED)\n# Add the pybind11 module to build targets\npybind11_add_module(basic_math MODULE src/basic_math.cpp)\ninstall(TARGETS basic_math DESTINATION ${SKBUILD_PROJECT_NAME})\n\n\n\nsrc/basic_math.cpp:\n#include &lt;pybind11/pybind11.h&gt;\nint add(int i, int j) { return i + j; }\nnamespace py = pybind11;\nPYBIND11_MODULE(basic_math, m) {\n  m.def(\"add\", &add, R\"pbdoc(\n      Add two numbers\n  )pbdoc\");\n...\n}\n\n\n\nInstalling locally is the same as for the pure-Python example:\n$ cd examples/simple_packaging\n$ python -m pip install --upgrade pip wheel\n$ python -m pip install .\nSuccessfully built rosen-cpp\nInstalling collected packages: rosen-cpp\nSuccessfully installed rosen-cpp-0.0.1\nModule name is that given in C++:\nfrom rosen_cpp import basic_math\nbasic_math.add(1, 2)\n# 3\n\n\n\nIf your code is publicly available on the WWW in a Git repository, you’ve already done a version of distribution!\n# General pattern is:\n# python -m pip install \"project @ git+https://example.com/repo/project.git@branch#subdirectory=path\"\n$ python -m pip install \\\n  \"git+https://github.com/matthewfeickert-talks/talk-urssi-summer-school-2024.git#subdirectory=examples/simple_packaging\"\n(more reasonable font size, and more common, example)\n# Works for pure-Python packages\n$ python -m pip install --upgrade \"git+https://github.com/scikit-hep/pyhf.git\"\n# as well as packages with compiled extensions\n$ python -m pip install --upgrade \"git+https://github.com/scikit-hep/iminuit.git\"\n\nIdeally we’d prefer a more organized approach: distribution through a package index\nFirst we need to create distributions of our packaged code.\nDistributions that pip can install:\n\nsource distribution (sdist): A tarfile (.tar.gz) of the source files of our package (subset of all the files in the repository)\nwheel: A zipfile (.whl) of the file system structure and package metadata with any dependencies prebuilt\n\nNo arbitrary code execution, only decompressing and copying of files\n\n\n\nTo create these distributions from source code, rely on our package build backend (e.g. hatchling) and build frontend tool like build\n$ python -m pip install --upgrade build\n$ python -m build .\n* Creating venv isolated environment...\n* Installing packages in isolated environment... (hatch-vcs&gt;=0.3.0, hatchling&gt;=1.13.0)\n* Getting build dependencies for sdist...\n* Building sdist...\n* Building wheel from sdist\n* Creating venv isolated environment...\n* Installing packages in isolated environment... (hatch-vcs&gt;=0.3.0, hatchling&gt;=1.13.0)\n* Getting build dependencies for wheel...\n* Building wheel...\nSuccessfully built rosen-0.0.1.tar.gz and rosen-0.0.1-py3-none-any.whl\n$ ls dist\nrosen-0.0.1-py3-none-any.whl  rosen-0.0.1.tar.gz\n\n\n\nCan now securely upload the distributions under ./dist/ to any package index that understands how to use them.\nThe most common is the Python Package Index (PyPI) which serves as the default package index for pip.\n\n\n\n\nThe conda family of package managers (conda, mamba, micromamba, pixi) take an alternative approach from pip.\nInstead of installing Python packages, they act as general purpose package managers and install all dependencies (including Python) as OS and architecture specific built binaries (.conda files — zipfile containing compressed tar files) hosted on conda-forge.\nAllows an additional level of runtime environment specification not possible with just pip, though getting environment solves right can become more complicated.\n\nPopular in scientific computing as arbitrary binaries can be hosted, including compilers (e.g. gcc, Fortran) and even the full NVIDIA CUDA stack!\nWith the change to full binaries only this also requires that specification of the environment being installed is important.\nWith sdists and wheels, if there is no compatible wheel available, pip will automatically fall back to trying to locally build from the sidst. Can’t do that if there is no matching .conda binary!\n\n\n\nHave been reasonably assuming that packaged code can be used in arbitrary environments with other code that is compatible (library-like).\nFor distributing code, this is probably the correct view, but your analysis is not a library. Your analysis is an application (a hand crafted implementation of code from libraries).\nWhile your analysis might run with arbitrary configurations of the defined libraries and runtimes (reusable) want to also have a hash-level specified version for reproduciblity: a lock file\n\n\n\nLock files are simple: A hash level record of every dependency in the environment.\nAllow for reproducibility by simply being an list of every file to download from the internet.\nShould be programmatically generated from a high level requirements file and maintained in version control with your analysis.\n\nFor pip: pip-tools, pdm, pipenv, poetry\nFor conda family: conda-lock, pixi\n\n\n\n\nThe approach of pixi is similar to Julia.\n\nProject.toml: describes the project on a high level\nManifest.toml: absolute record of the state of the packages in the environment (a lock file)\n\n\nJulia’s package manager Pkg.jl provides users a high level interface to edit Project.toml and then automatically updates Manifest.toml in response. Reproducibility of environment by default!\n\n\nLibrary: Project.toml in version control\nApplication: Project.toml and Manifest.toml in version control\n\n\n\n\n\nFull environment specification with Linux (Open Container Initiative (OCI)) container images (Docker, Apptainer, Podman)\nOrchestration of multiple environments inside of an analysis\n\nUsing workflow languages\n\nThe difficult realities of long term preservation\n\nAssumptions of present technologies don’t translate forever into the future, infrastructure goes away\nHow to store files that aren’t “code” (e.g. images, training data, database files) — c.f. Zenodo\n\nWhat analysis reuse looks like\n\nRECAST(particle physics)\n\n\n\n\n\nDon’t start your next Python project from scratch! Use the Scientific Python library development Cookiecutter: cookie\n$ pipx install cookiecutter\n$ cookiecutter gh:scientific-python/cookie\n#  [1/14] The name of your project (package):\n# ...\ncookie will setup your repository for you with templated layouts for 11 different build backends and adheres to packaging and development best practices.\n\n\n\nPackaging standards and best practices continue to change and get better. Instead of trying to maintain your own resources follow and engage with community resources created by the teams that are building the tools and infrastructure.\n\n\n\nScientific Python Library Development Guide\n\n\n\n\n\nFind and start working with Research Software Engineers (RSE).\n\nI don’t think that most scientists care/get excited about learning packaging tools. We just want things to work. RSEs can make that easier and are SUPER knowledgeable!\n\nI’m among the “not excited”. I care about packaging because I care about reusable tools for science.\n\n\n\n\n\n\nSociety of Research Software Engineering\n\n\n\n\n\n\nVersioned archive of everything: code, documents, data products, data sets\n\n\n\n\n\nDOI for project and each version\n\n\n\n\n\n\n\n\n\n\nWhirlwind tour of lifting analysis code from version control, to packages, distributed binaries, and the rest of the world\nNot a hopeless bog of technical debt, but community infrastructure built by people who you can collaborate with\nReusable code can be a nucleation point for communities\n\n\n\n\n\nLevel Up Your Python, Henry Schreiner\nPython Packaging User Guide, Packaging Python Projects Tutorial, The PyPA\nScientific Python Library Development Guide, Scientific Python (originally made by Scikit-HEP)\ncookie, Scientific Python (originally made by Scikit-HEP)\nINTERSECT’s packaging tutorial, INTERSECT"
  },
  {
    "objectID": "package_distribution.html#hypothetical-workflow-for-the-typical-scientist",
    "href": "package_distribution.html#hypothetical-workflow-for-the-typical-scientist",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Work on idea for paper with collaborators\nDo exploratory analysis in scripts and Jupyter ecosystem\nAs research progresses need to write more complicated functions and workflows\nCode begins to sprawl across multiple directories\nSoftware dependencies begin to become more complicated\nThe code “works on my machine”, but what about your collaborators?\n\n\nPeople heroically press forward, but this is painful, and not reusable"
  },
  {
    "objectID": "package_distribution.html#reusable-science-step-by-step",
    "href": "package_distribution.html#reusable-science-step-by-step",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "In this first scenario, you will probably see a lot of sys.path manipulation and utils.py\n$ tree examples/edit_sys_path\nexamples/edit_sys_path\n├── code\n│   └── utils.py  # helper functions rosen, rosen_der\n├── example.py  # want to import rosen, rosen_der\n└── jupytext.toml\n\n1 directory, 3 files"
  },
  {
    "objectID": "package_distribution.html#section",
    "href": "package_distribution.html#section",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "# example.py\nimport sys\nfrom pathlib import Path\n# Make ./code/utils.py visible to sys.path\n# sys.path[1] should be after cwd and before virtual environment\nsys.path.insert(1, str(Path(__file__).parent / \"code\"))\nfrom utils import rosen, rosen_der\nx0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\nresult = minimize(rosen, x0, method=\"BFGS\",\n                  jac=rosen_der, options={\"disp\": True})\noptimized_params = result.x\n# array([1.00000004, 1.0000001 , 1.00000021, 1.00000044, 1.00000092])\n\n\nThis is already better than having everything in a single massive file\nHowever, now things are tied to this relative path on your computer\n\n# Make ./code/utils.py visible to sys.path\nsys.path.insert(1, str(Path(__file__).parent / \"code\"))\nfrom utils import rosen, rosen_der\n\nand are brittle to refactoring and change\n\nBut we can do much better!"
  },
  {
    "objectID": "package_distribution.html#next-steps-packaging-your-code",
    "href": "package_distribution.html#next-steps-packaging-your-code",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Real emphasis is just that your code is now installable\n\nAnywhere your Python virtual environment is active you can use your code\n\nSo following The Zen of Python this should be very straightforward?\n\n\n$ python -c 'import this' | grep obvious\nThere should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch."
  },
  {
    "objectID": "package_distribution.html#section-1",
    "href": "package_distribution.html#section-1",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Maybe not so much. :(\n\n\n\n\n\n\nYou might be asking: Why is there more than one thing?\n\nThe good news: Python packaging has improved dramatically in the last 5 years\n- It has never been easier to just point your package manager to some code locally, or on the internet, and get working Python code installed and running on your machine regardless of operating system or architecture\n\n- This is a small miracle\nThe bad news: Python packaging has expanded dramatically in the last 5 years\n- By creating standards the PyPA allowed for an ecosystem of packaging backends to be created to tackle various problems (this is good!)\n\n- This means that our The Zen of Python expectations are violated and we need to make design choices (hard for beginners)\n\nThe okay news: You can probably default to the simplest thing\npure Python: Probably hatch compiled extensions: Probably setuptools + pybind11 or scikit-build-core + pybind11\n\n\n\n\n\nPython Packaging User Guide, Packaging Python Projects Tutorial\n\n\n\n\n\n\nScientific Python Library Development Guide"
  },
  {
    "objectID": "package_distribution.html#simple-packaging-example",
    "href": "package_distribution.html#simple-packaging-example",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Modern PEP 518 compliant build backends just need a single file: pyproject.toml\n$ tree examples/simple_packaging\nexamples/simple_packaging\n\n├── LICENSE\n├── pyproject.toml  # controls packaging and interactions with tools\n├── README.md\n├── src\n│   └── rosen\n│       ├── example.py\n│       ├── __init__.py\n│       └── _version.py\n└── tests\n    └── test_example.py\n\n3 directories, 7 files"
  },
  {
    "objectID": "package_distribution.html#simple-packaging-example-pyproject.toml",
    "href": "package_distribution.html#simple-packaging-example-pyproject.toml",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "What is .toml?\n“TOML aims to be a minimal configuration file format that’s easy to read due to obvious semantics. TOML is designed to map unambiguously to a hash table. TOML should be easy to parse into data structures in a wide variety of languages.” — https://toml.io/ (emphasis mine)\nIn recent years TOML has seen a rise in popularity for configuration files and lock files. Things that need to be easy to read (humans) and easy to parse (machines)."
  },
  {
    "objectID": "package_distribution.html#section-2",
    "href": "package_distribution.html#section-2",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Defining how your project should get built\n[build-system]\nrequires = [\n    \"hatchling&gt;=1.13.0\",\n    \"hatch-vcs&gt;=0.3.0\",\n]\nbuild-backend = \"hatchling.build\"\n...\n\nDefining project metadata and requirements\n[project]\nname = \"rosen\"\ndynamic = [\"version\"]\ndescription = \"Example package for demonstration\"\nreadme = \"README.md\"\nlicense = { text = \"MIT\" }  # SPDX short identifier\nauthors = [\n  { name = \"Matthew Feickert\", email = \"matthew.feickert@cern.ch\" },\n]\nrequires-python = \"&gt;=3.8\"\ndependencies = [\n    \"scipy&gt;=1.6.0\",\n    \"numpy\",  # compatible versions controlled through scipy\n]\n...\n\nConfiguring tooling options and interactions with other tools\n[tool.hatch.version]\nsource = \"vcs\"\n[tool.hatch.version.raw-options]\nlocal_scheme = \"no-local-version\"\n# Need to give root as we aren't at the same level as the git repo\nroot = \"../..\"\n[tool.hatch.build.hooks.vcs]\nversion-file = \"src/rosen/_version.py\"\n..."
  },
  {
    "objectID": "package_distribution.html#simple-packaging-example-installing-your-code",
    "href": "package_distribution.html#simple-packaging-example-installing-your-code",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "You can now locally install your package into your Python virtual environment\n$ cd examples/simple_packaging\n$ python -m pip install --upgrade pip wheel\n$ python -m pip install .\nSuccessfully built rosen\nInstalling collected packages: rosen\nSuccessfully installed rosen-0.0.1\n$ python -m pip show rosen\nName: rosen\nVersion: 0.0.1\nSummary: Example package for demonstration\nHome-page:\nAuthor:\nAuthor-email: Matthew Feickert &lt;matthew.feickert@cern.ch&gt;\nLicense: MIT\nLocation: ***/lib/python3.12/site-packages\nRequires: numpy, scipy\nRequired-by:\n\nand use it anywhere\n# example.py\nimport numpy as np\nfrom scipy.optimize import minimize\n# We can now import our code\nfrom rosen.example import rosen, rosen_der\nx0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\nresult = minimize(rosen, x0, method=\"BFGS\",\n                  jac=rosen_der, options={\"disp\": True})\noptimized_params = result.x\n# array([1.00000004, 1.0000001 , 1.00000021, 1.00000044, 1.00000092])"
  },
  {
    "objectID": "package_distribution.html#packaging-doesnt-slow-down-development",
    "href": "package_distribution.html#packaging-doesnt-slow-down-development",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "PEP 518 compliant build backends allow for “editable installs”\n$ python -m pip install --upgrade --editable .\n$ python -m pip show rosen | grep --ignore-case 'location'\nLocation: ***/lib/python3.12/site-packages\nEditable project location: ***/examples/simple_packaging\nEditable installs add the files in the development directory to Python’s import path. (Only need to re-installation if you change the project metadata.)\nCan develop your code under src/ and have immediate access to it"
  },
  {
    "objectID": "package_distribution.html#packaging-compiled-extensions",
    "href": "package_distribution.html#packaging-compiled-extensions",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "With modern packaging infrastructure, packaging compiled extensions requires small extra work\n$ tree examples/compiled_packaging\n\nexamples/compiled_packaging\n├── CMakeLists.txt  # Addition of CMake\n├── LICENSE\n├── pyproject.toml  # build backend change\n├── README.md\n├── src\n│   ├── basic_math.cpp  # C++ extension\n│   └── rosen_cpp\n│       ├── example.py\n│       └── __init__.py\n└── tests\n    └── test_example.py\n\n3 directories, 8 files"
  },
  {
    "objectID": "package_distribution.html#section-3",
    "href": "package_distribution.html#section-3",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "pyproject.toml:\nSwap build system to scikit-build-core + pybind11\n[build-system]\nrequires = [\n  \"scikit-build-core\",\n  \"pybind11\"\n  ]\nbuild-backend = \"scikit_build_core.build\"\n..."
  },
  {
    "objectID": "package_distribution.html#section-4",
    "href": "package_distribution.html#section-4",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "CMakeLists.txt:\n# Specify CMake version and project language\ncmake_minimum_required(VERSION 3.15...3.30)\nproject(${SKBUILD_PROJECT_NAME} LANGUAGES CXX)\n# Setup pybind11\nset(PYBIND11_FINDPYTHON ON)\nfind_package(pybind11 CONFIG REQUIRED)\n# Add the pybind11 module to build targets\npybind11_add_module(basic_math MODULE src/basic_math.cpp)\ninstall(TARGETS basic_math DESTINATION ${SKBUILD_PROJECT_NAME})"
  },
  {
    "objectID": "package_distribution.html#section-5",
    "href": "package_distribution.html#section-5",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "src/basic_math.cpp:\n#include &lt;pybind11/pybind11.h&gt;\nint add(int i, int j) { return i + j; }\nnamespace py = pybind11;\nPYBIND11_MODULE(basic_math, m) {\n  m.def(\"add\", &add, R\"pbdoc(\n      Add two numbers\n  )pbdoc\");\n...\n}"
  },
  {
    "objectID": "package_distribution.html#packaging-compiled-extensions-installing",
    "href": "package_distribution.html#packaging-compiled-extensions-installing",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Installing locally is the same as for the pure-Python example:\n$ cd examples/simple_packaging\n$ python -m pip install --upgrade pip wheel\n$ python -m pip install .\nSuccessfully built rosen-cpp\nInstalling collected packages: rosen-cpp\nSuccessfully installed rosen-cpp-0.0.1\nModule name is that given in C++:\nfrom rosen_cpp import basic_math\nbasic_math.add(1, 2)\n# 3"
  },
  {
    "objectID": "package_distribution.html#going-further-distributing-packages",
    "href": "package_distribution.html#going-further-distributing-packages",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "If your code is publicly available on the WWW in a Git repository, you’ve already done a version of distribution!\n# General pattern is:\n# python -m pip install \"project @ git+https://example.com/repo/project.git@branch#subdirectory=path\"\n$ python -m pip install \\\n  \"git+https://github.com/matthewfeickert-talks/talk-urssi-summer-school-2024.git#subdirectory=examples/simple_packaging\"\n(more reasonable font size, and more common, example)\n# Works for pure-Python packages\n$ python -m pip install --upgrade \"git+https://github.com/scikit-hep/pyhf.git\"\n# as well as packages with compiled extensions\n$ python -m pip install --upgrade \"git+https://github.com/scikit-hep/iminuit.git\"\n\nIdeally we’d prefer a more organized approach: distribution through a package index\nFirst we need to create distributions of our packaged code.\nDistributions that pip can install:\n\nsource distribution (sdist): A tarfile (.tar.gz) of the source files of our package (subset of all the files in the repository)\nwheel: A zipfile (.whl) of the file system structure and package metadata with any dependencies prebuilt\n\nNo arbitrary code execution, only decompressing and copying of files\n\n\n\nTo create these distributions from source code, rely on our package build backend (e.g. hatchling) and build frontend tool like build\n$ python -m pip install --upgrade build\n$ python -m build .\n* Creating venv isolated environment...\n* Installing packages in isolated environment... (hatch-vcs&gt;=0.3.0, hatchling&gt;=1.13.0)\n* Getting build dependencies for sdist...\n* Building sdist...\n* Building wheel from sdist\n* Creating venv isolated environment...\n* Installing packages in isolated environment... (hatch-vcs&gt;=0.3.0, hatchling&gt;=1.13.0)\n* Getting build dependencies for wheel...\n* Building wheel...\nSuccessfully built rosen-0.0.1.tar.gz and rosen-0.0.1-py3-none-any.whl\n$ ls dist\nrosen-0.0.1-py3-none-any.whl  rosen-0.0.1.tar.gz"
  },
  {
    "objectID": "package_distribution.html#section-6",
    "href": "package_distribution.html#section-6",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Can now securely upload the distributions under ./dist/ to any package index that understands how to use them.\nThe most common is the Python Package Index (PyPI) which serves as the default package index for pip."
  },
  {
    "objectID": "package_distribution.html#distributing-packages-conda-forge",
    "href": "package_distribution.html#distributing-packages-conda-forge",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "The conda family of package managers (conda, mamba, micromamba, pixi) take an alternative approach from pip.\nInstead of installing Python packages, they act as general purpose package managers and install all dependencies (including Python) as OS and architecture specific built binaries (.conda files — zipfile containing compressed tar files) hosted on conda-forge.\nAllows an additional level of runtime environment specification not possible with just pip, though getting environment solves right can become more complicated.\n\nPopular in scientific computing as arbitrary binaries can be hosted, including compilers (e.g. gcc, Fortran) and even the full NVIDIA CUDA stack!\nWith the change to full binaries only this also requires that specification of the environment being installed is important.\nWith sdists and wheels, if there is no compatible wheel available, pip will automatically fall back to trying to locally build from the sidst. Can’t do that if there is no matching .conda binary!"
  },
  {
    "objectID": "package_distribution.html#defining-the-environment-application-vs.-library",
    "href": "package_distribution.html#defining-the-environment-application-vs.-library",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Have been reasonably assuming that packaged code can be used in arbitrary environments with other code that is compatible (library-like).\nFor distributing code, this is probably the correct view, but your analysis is not a library. Your analysis is an application (a hand crafted implementation of code from libraries).\nWhile your analysis might run with arbitrary configurations of the defined libraries and runtimes (reusable) want to also have a hash-level specified version for reproduciblity: a lock file"
  },
  {
    "objectID": "package_distribution.html#defining-the-environment-lock-file",
    "href": "package_distribution.html#defining-the-environment-lock-file",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Lock files are simple: A hash level record of every dependency in the environment.\nAllow for reproducibility by simply being an list of every file to download from the internet.\nShould be programmatically generated from a high level requirements file and maintained in version control with your analysis.\n\nFor pip: pip-tools, pdm, pipenv, poetry\nFor conda family: conda-lock, pixi"
  },
  {
    "objectID": "package_distribution.html#defining-the-environment-comparing-to-julia",
    "href": "package_distribution.html#defining-the-environment-comparing-to-julia",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "The approach of pixi is similar to Julia.\n\nProject.toml: describes the project on a high level\nManifest.toml: absolute record of the state of the packages in the environment (a lock file)\n\n\nJulia’s package manager Pkg.jl provides users a high level interface to edit Project.toml and then automatically updates Manifest.toml in response. Reproducibility of environment by default!\n\n\nLibrary: Project.toml in version control\nApplication: Project.toml and Manifest.toml in version control"
  },
  {
    "objectID": "package_distribution.html#areas-still-to-discuss-another-time",
    "href": "package_distribution.html#areas-still-to-discuss-another-time",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Full environment specification with Linux (Open Container Initiative (OCI)) container images (Docker, Apptainer, Podman)\nOrchestration of multiple environments inside of an analysis\n\nUsing workflow languages\n\nThe difficult realities of long term preservation\n\nAssumptions of present technologies don’t translate forever into the future, infrastructure goes away\nHow to store files that aren’t “code” (e.g. images, training data, database files) — c.f. Zenodo\n\nWhat analysis reuse looks like\n\nRECAST(particle physics)"
  },
  {
    "objectID": "package_distribution.html#recommendations-tooling",
    "href": "package_distribution.html#recommendations-tooling",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Don’t start your next Python project from scratch! Use the Scientific Python library development Cookiecutter: cookie\n$ pipx install cookiecutter\n$ cookiecutter gh:scientific-python/cookie\n#  [1/14] The name of your project (package):\n# ...\ncookie will setup your repository for you with templated layouts for 11 different build backends and adheres to packaging and development best practices."
  },
  {
    "objectID": "package_distribution.html#recommendations-community-guides",
    "href": "package_distribution.html#recommendations-community-guides",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Packaging standards and best practices continue to change and get better. Instead of trying to maintain your own resources follow and engage with community resources created by the teams that are building the tools and infrastructure.\n\n\n\nScientific Python Library Development Guide"
  },
  {
    "objectID": "package_distribution.html#recommendations-collaboration",
    "href": "package_distribution.html#recommendations-collaboration",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Find and start working with Research Software Engineers (RSE).\n\nI don’t think that most scientists care/get excited about learning packaging tools. We just want things to work. RSEs can make that easier and are SUPER knowledgeable!\n\nI’m among the “not excited”. I care about packaging because I care about reusable tools for science.\n\n\n\n\n\n\nSociety of Research Software Engineering"
  },
  {
    "objectID": "package_distribution.html#recommendations-zenodo",
    "href": "package_distribution.html#recommendations-zenodo",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Versioned archive of everything: code, documents, data products, data sets\n\n\n\n\n\nDOI for project and each version"
  },
  {
    "objectID": "package_distribution.html#summary",
    "href": "package_distribution.html#summary",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Whirlwind tour of lifting analysis code from version control, to packages, distributed binaries, and the rest of the world\nNot a hopeless bog of technical debt, but community infrastructure built by people who you can collaborate with\nReusable code can be a nucleation point for communities"
  },
  {
    "objectID": "package_distribution.html#references",
    "href": "package_distribution.html#references",
    "title": "Distributing your Science: Turning analyses into scientific tools",
    "section": "",
    "text": "Level Up Your Python, Henry Schreiner\nPython Packaging User Guide, Packaging Python Projects Tutorial, The PyPA\nScientific Python Library Development Guide, Scientific Python (originally made by Scikit-HEP)\ncookie, Scientific Python (originally made by Scikit-HEP)\nINTERSECT’s packaging tutorial, INTERSECT"
  },
  {
    "objectID": "collaboration-revealjs.html#lesson-objectives",
    "href": "collaboration-revealjs.html#lesson-objectives",
    "title": "Collaboration with Git and Github",
    "section": "Lesson Objectives",
    "text": "Lesson Objectives\n\nReview git commands\nDescribe individual and collaborative workflows with git\nIntroduce git commands for collaborative workflows\nDemo of collaborative workflows in practice\nSee additional useful git tips/tricks"
  },
  {
    "objectID": "collaboration-revealjs.html#acknowledgements",
    "href": "collaboration-revealjs.html#acknowledgements",
    "title": "Collaboration with Git and Github",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis material is heavily influenced by the previous works of Madicken Munk, Karthik Ram and James Howison from the previous summer and winter schools.\nOther helpful/fun resources for git\nhttps://git-school.github.io/visualizing-git/ https://pcottle.github.io/learnGitBranching/?NODEMO https://allisonhorst.com/git-github https://jvns.ca/blog/2023/11/23/branches-intuition-reality/ https://git-scm.com/docs https://swcarpentry.github.io/git-novice/"
  },
  {
    "objectID": "collaboration-revealjs.html#workflows-with-git-an-individual-workflow-without-a-remote",
    "href": "collaboration-revealjs.html#workflows-with-git-an-individual-workflow-without-a-remote",
    "title": "Collaboration with Git and Github",
    "section": "Workflows with Git: An Individual Workflow (without a remote)",
    "text": "Workflows with Git: An Individual Workflow (without a remote)\ncommit, commit, commit …..\ndanikamacdonell@computer: ~/Git$ mkdir research-code ; cd research-code\ndanikamacdonell@computer: ~/Git/research-code$ git init\nInitialized empty Git repository in /Users/danikamacdonell/Git/research-code/.git/\ndanikamacdonell@computer: ~/Git/research-code$ git branch -M main\ndanikamacdonell@computer: ~/Git/research-code$ touch README.md ; open README.md\ndanikamacdonell@computer: ~/Git/research-code$ git add README.md\ndanikamacdonell@computer: ~/Git/research-code$ git commit -m 'add README with code description'\n[main (root-commit) 49c9e77] add README with code description\n 1 file changed, 0 insertions(+), 0 deletions(-)\n     create mode 100644 README.md\ndanikamacdonell@computer: ~/Git/research-code$ git log\nAuthor: Danika MacDonell &lt;danikamacdonell@computer&gt;\n    Add a README with code description"
  },
  {
    "objectID": "collaboration-revealjs.html#an-individual-workflow-with-a-remote",
    "href": "collaboration-revealjs.html#an-individual-workflow-with-a-remote",
    "title": "Collaboration with Git and Github",
    "section": "An Individual Workflow (with a remote)",
    "text": "An Individual Workflow (with a remote)"
  },
  {
    "objectID": "collaboration-revealjs.html#but-what-about-working-with-others",
    "href": "collaboration-revealjs.html#but-what-about-working-with-others",
    "title": "Collaboration with Git and Github",
    "section": "… But what about working with others?",
    "text": "… But what about working with others?"
  },
  {
    "objectID": "collaboration-revealjs.html#centralized-workflow",
    "href": "collaboration-revealjs.html#centralized-workflow",
    "title": "Collaboration with Git and Github",
    "section": "Centralized Workflow",
    "text": "Centralized Workflow\nAll members work on the same repository\ngit pull before starting work\nEveryone commits to main\ngit push\nIf there is no merge conflict, 🙌\nOtherwise fix merge conflict, then push"
  },
  {
    "objectID": "collaboration-revealjs.html#feature-branching-workflow",
    "href": "collaboration-revealjs.html#feature-branching-workflow",
    "title": "Collaboration with Git and Github",
    "section": "Feature Branching Workflow",
    "text": "Feature Branching Workflow\nMembers work on the same repository but use individual branches to do feature development"
  },
  {
    "objectID": "collaboration-revealjs.html#section",
    "href": "collaboration-revealjs.html#section",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Create and switch to a branch\nAdd commits\nPush feature branch to GitHub\nStart a pull request\nDiscuss, add more commits, merge"
  },
  {
    "objectID": "collaboration-revealjs.html#section-1",
    "href": "collaboration-revealjs.html#section-1",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Some important commands for this workflow:\n\ngit branch\ngit checkout -b &lt;branchname&gt;\ngit push -u origin &lt;branchname&gt;\n\n\n.. add some more commits, then git push and open a pull request"
  },
  {
    "objectID": "collaboration-revealjs.html#pull-requests",
    "href": "collaboration-revealjs.html#pull-requests",
    "title": "Collaboration with Git and Github",
    "section": "Pull Requests",
    "text": "Pull Requests\nPull requests are an excellent tool for fostering code review. If you’re using Github for team projects,you should be using these extensively."
  },
  {
    "objectID": "collaboration-revealjs.html#pull-request-best-practices",
    "href": "collaboration-revealjs.html#pull-request-best-practices",
    "title": "Collaboration with Git and Github",
    "section": "Pull request best practices:",
    "text": "Pull request best practices:\n\nTry to make frequent, targeted pull requests that add a specific feature or set of features\n\n✅ “Adds a new click feature for area layers in the geospatial mapping tool”\n❌ “Adds the last 3 years of my thesis work”\n\nItemize each major addition.\n\n\nA good practice is for someone else to merge your code into main, after being approved by at least one colleague. Sometimes a reviewer may not have merge rights; in these cases the requirement may be an approving review must be given before the feature is merged."
  },
  {
    "objectID": "collaboration-revealjs.html#pull-request-tip",
    "href": "collaboration-revealjs.html#pull-request-tip",
    "title": "Collaboration with Git and Github",
    "section": "Pull request tip:",
    "text": "Pull request tip:\nUsing the github interface, you can change the target of a pull request. The default is to the main branch, but it could be another feature branch. This can be used if you want to help develop a feature branch outside of main with a collaborator.\n⛔️ Never send a large pull request without notice 🙅"
  },
  {
    "objectID": "collaboration-revealjs.html#demo-update-summerschool-july2024-link-to-issue",
    "href": "collaboration-revealjs.html#demo-update-summerschool-july2024-link-to-issue",
    "title": "Collaboration with Git and Github",
    "section": "Demo: Update summerschool-July2024 (link to issue)",
    "text": "Demo: Update summerschool-July2024 (link to issue)\n[...]: ~/Git/research-code$ cd ../summerschool-July2024\n[...]: ~/Git/summerschool-July2024$ git checkout -b update-git-lesson\n[...]: ~/Git/summerschool-July2024$ open README.md\n[...]: ~/Git/summerschool-July2024$ git add README.md\n[...]: ~/Git/summerschool-July2024$ git commit -m \"Updating the Git/GitHub lesson.\"\n[...]: ~/Git/summerschool-July2024$ git push -u origin add-git-lesson\nClose the issue!"
  },
  {
    "objectID": "collaboration-revealjs.html#practice",
    "href": "collaboration-revealjs.html#practice",
    "title": "Collaboration with Git and Github",
    "section": "Practice",
    "text": "Practice\ncd ../research-code\nUsing the feature branching workflow:\n\nUse at least two commits to:\n\nCreate a python script in the source directory called PrintMessage.py that prints a simple message.\nAdd a new section to the README to document the new script.\n\nMake a pull request!"
  },
  {
    "objectID": "collaboration-revealjs.html#forking-workflow",
    "href": "collaboration-revealjs.html#forking-workflow",
    "title": "Collaboration with Git and Github",
    "section": "Forking Workflow",
    "text": "Forking Workflow\nIn this workflow each collaborator “forks” a copy of the centralized repository. These forks represent individual remote repositories for each collaborator. Collaborators submit pull requests from their forks to the centralized repository.\n\nWhen do I need to fork?\n\n\nIf you don’t have write access and want to suggest changes, forking makes sense.\nIf you’re an active project collaborator with write access, use the branching workflow."
  },
  {
    "objectID": "collaboration-revealjs.html#forking-workflow-guidelines",
    "href": "collaboration-revealjs.html#forking-workflow-guidelines",
    "title": "Collaboration with Git and Github",
    "section": "Forking Workflow Guidelines",
    "text": "Forking Workflow Guidelines\nEveryone has a fork of a “central” repository\nAdd commits to feature branches\nPush feature branches to individual forks\nSend pull-request from feature branch on fork to central repository"
  },
  {
    "objectID": "collaboration-revealjs.html#extra-tips",
    "href": "collaboration-revealjs.html#extra-tips",
    "title": "Collaboration with Git and Github",
    "section": "Extra Tips:",
    "text": "Extra Tips:\n\nTip #1: Always git pull before you start new work\nTip #2: Keep branch names descriptive\nTip #3: Generously use branches (but delete them when they’re merged or stale)\nTip #4: Use github command line tool (gh) to simplify your workflow"
  },
  {
    "objectID": "collaboration-revealjs.html#practice-1",
    "href": "collaboration-revealjs.html#practice-1",
    "title": "Collaboration with Git and Github",
    "section": "Practice",
    "text": "Practice\nMake a fork of https://github.com/mcsc-impact-climate/urssi-research-code and Using the forking workflow, update the script source/PrintMessage.py to instead print out your name (or something similarly personalized).\n\ndanikamacdonell@computer: ~/Git/research-code$ cd ..\ndanikamacdonell@computer: ~/Git$ git clone git@github.com:danikam/urssi-research-code.git\ndanikamacdonell@computer: ~/Git$ cd urssi-research-code\ndanikamacdonell@computer: ~/Git$ git remote add upstream git@github.com:mcsc-impact-climate/urssi-research-code.git\ndanikamacdonell@computer: ~/Git$ git checkout -b personalize-message\nAdd your new file(s), push and open a pull request"
  },
  {
    "objectID": "collaboration-revealjs.html#more-useful-git-commands",
    "href": "collaboration-revealjs.html#more-useful-git-commands",
    "title": "Collaboration with Git and Github",
    "section": "More useful git commands",
    "text": "More useful git commands\nRebasing\nRebasing lets you pull new commits from the parent branch or upstream repo (if you’re on a fork).\nFrom parent branch:\ngit fetch origin\ngit rebase origin/&lt;parent-branch&gt;\nFrom upstream forked repo:\ngit remote add upstream https://github.com/original-owner/repo.git\ngit fetch upstream\ngit rebase upstream/&lt;parent-branch&gt;"
  },
  {
    "objectID": "collaboration-revealjs.html#section-2",
    "href": "collaboration-revealjs.html#section-2",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "tagging commits\nbranches are special labels that track a series of commits, but what if you want a special name for a particular commit (like when you released a new version of your code)? you can “tag” these\n\ngit tag -a &lt;tagname&gt; &lt;hash&gt; – useful for tagging a particular commit farther back in history\ngit tag -a &lt;tagname&gt; -m \"tag message\" – this should tag the current commit with a descriptive message\ngit push origin &lt;tagname&gt; – push a particular tag up to your remote\ngit push origin --tags – push all of your tags up to your remote"
  },
  {
    "objectID": "collaboration-revealjs.html#section-3",
    "href": "collaboration-revealjs.html#section-3",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "amending a commit\nOh no! I made a typo in my commit message!\ngit commit --amend is useful for both fixing commit messages and for adding in files that were supposed to be committed and werent"
  },
  {
    "objectID": "collaboration-revealjs.html#section-4",
    "href": "collaboration-revealjs.html#section-4",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "cherry picking\nWhat if you have a commit that really belongs on a different branch? Or in development you fixed a bug that you think should be in its own PR? You can “cherry pick” that commit to a new branch.\ngit cherry-pick &lt;hash&gt;"
  },
  {
    "objectID": "collaboration-revealjs.html#section-5",
    "href": "collaboration-revealjs.html#section-5",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "undoing changes\nReverting vs. Restoring\ngit revert &lt;commit hash&gt;\ngit restore &lt;filename&gt;"
  },
  {
    "objectID": "collaboration-revealjs.html#section-6",
    "href": "collaboration-revealjs.html#section-6",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "stashing changes\noh no! I started making changes but I’m not on the feature branch I thought I was!\ngit stash can be used to hide the changes in your working tree and then bring them back out with git stash apply when you’re on the appropriate branch"
  },
  {
    "objectID": "collaboration-revealjs.html#section-7",
    "href": "collaboration-revealjs.html#section-7",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "co-authoring changes\nHave you pair programmed with a friend and come up with a solution together? How do you deal with attribution?\nCo-authored-by: NAME &lt;EMAIL&gt; can add multiple authors to a commit."
  },
  {
    "objectID": "collaboration-revealjs.html#more-resources",
    "href": "collaboration-revealjs.html#more-resources",
    "title": "Collaboration with Git and Github",
    "section": "More resources",
    "text": "More resources\n\nGitHub Issues help you share code issues or feature requests with collaborators\nDo you need to version control large files? git lfs and git annex are tools designed to help with this\nHow to undo almost anything with git link\nRemove sensitive data (like private keys) from a repository link"
  },
  {
    "objectID": "collaboration-revealjs.html#exercises",
    "href": "collaboration-revealjs.html#exercises",
    "title": "Collaboration with Git and Github",
    "section": "Exercises",
    "text": "Exercises\nChoose one of the following:\n\nIf you brought a project to work on: open an issue on your repository for something you’d like to improve that’s a beginner friendly issue. Describe the issue thoroughly. Then, working in groups at your tables, have a partner fork your project and submit a pull request fixing that issue. Do not merge the pull request today.\nMake a feature branch on your project and add a simple new feature to your project (could even just be some new info in the README). Submit a pull request on your project using that branch. Do not merge the pull request today."
  },
  {
    "objectID": "collaboration.html",
    "href": "collaboration.html",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Review git commands\nDescribe individual and collaborative workflows with git\nIntroduce git commands for collaborative workflows\nDemo of collaborative workflows in practice\nSee additional useful git tips/tricks\n\n\n\n\nThis material is heavily influenced by the previous works of Madicken Munk, Karthik Ram and James Howison from the previous summer and winter schools.\nOther helpful/fun resources for git\nhttps://git-school.github.io/visualizing-git/ https://pcottle.github.io/learnGitBranching/?NODEMO https://allisonhorst.com/git-github https://jvns.ca/blog/2023/11/23/branches-intuition-reality/ https://git-scm.com/docs https://swcarpentry.github.io/git-novice/\n\n\n\ncommit, commit, commit …..\ndanikamacdonell@computer: ~/Git$ mkdir research-code ; cd research-code\ndanikamacdonell@computer: ~/Git/research-code$ git init\nInitialized empty Git repository in /Users/danikamacdonell/Git/research-code/.git/\ndanikamacdonell@computer: ~/Git/research-code$ git branch -M main\ndanikamacdonell@computer: ~/Git/research-code$ touch README.md ; open README.md\ndanikamacdonell@computer: ~/Git/research-code$ git add README.md\ndanikamacdonell@computer: ~/Git/research-code$ git commit -m 'add README with code description'\n[main (root-commit) 49c9e77] add README with code description\n 1 file changed, 0 insertions(+), 0 deletions(-)\n     create mode 100644 README.md\ndanikamacdonell@computer: ~/Git/research-code$ git log\nAuthor: Danika MacDonell &lt;danikamacdonell@computer&gt;\n    Add a README with code description\n\n\n\n\n\ncommit push, commit commit push, commit push …..\ndanikamacdonell@computer: ~/Git/research-code$ git remote add origin git@github.com:danikam/research-code.git\ndanikamacdonell@computer: ~/Git/research-code$ git push -u origin main\nEnumerating objects: 3, done.\n[...]\nTo github.com:danikam/research-code.git\n * [new branch]      main -&gt; main\nbranch 'main' set up to track 'origin/main'.\nWith your code on a remote (like GitHub, GitLab, or an internal server for your lab), your work is easily accessed by peers!\n💡GitLab and other Git platforms will have slightly different interfaces and features from GitHub, but the basic actions are generally pretty similar.\n\n\n\n\n\n\nAll members work on the same repository\ngit pull before starting work\nEveryone commits to main\ngit push\nIf there is no merge conflict, 🙌\nOtherwise fix merge conflict, then push\n\n\n\nMembers work on the same repository but use individual branches to do feature development\n\n\n\nCreate and switch to a branch\nAdd commits\nPush feature branch to GitHub\nStart a pull request\nDiscuss, add more commits, merge\n\n\n\nSome important commands for this workflow:\n\ngit branch\ngit checkout -b &lt;branchname&gt;\ngit push -u origin &lt;branchname&gt;\n\n\n.. add some more commits, then git push and open a pull request\n\n\n\n\nPull requests are an excellent tool for fostering code review. If you’re using Github for team projects,you should be using these extensively.\n\n\n\n\nTry to make frequent, targeted pull requests that add a specific feature or set of features\n\n✅ “Adds a new click feature for area layers in the geospatial mapping tool”\n❌ “Adds the last 3 years of my thesis work”\n\nItemize each major addition.\n\n\nA good practice is for someone else to merge your code into main, after being approved by at least one colleague. Sometimes a reviewer may not have merge rights; in these cases the requirement may be an approving review must be given before the feature is merged.\n\n\n\n\nUsing the github interface, you can change the target of a pull request. The default is to the main branch, but it could be another feature branch. This can be used if you want to help develop a feature branch outside of main with a collaborator.\n⛔️ Never send a large pull request without notice 🙅\n\n\n\n[...]: ~/Git/research-code$ cd ../summerschool-July2024\n[...]: ~/Git/summerschool-July2024$ git checkout -b update-git-lesson\n[...]: ~/Git/summerschool-July2024$ open README.md\n[...]: ~/Git/summerschool-July2024$ git add README.md\n[...]: ~/Git/summerschool-July2024$ git commit -m \"Updating the Git/GitHub lesson.\"\n[...]: ~/Git/summerschool-July2024$ git push -u origin add-git-lesson\nClose the issue!\n\n\n\ncd ../research-code\nUsing the feature branching workflow:\n\nUse at least two commits to:\n\nCreate a python script in the source directory called PrintMessage.py that prints a simple message.\nAdd a new section to the README to document the new script.\n\nMake a pull request!\n\n\n\n\nIn this workflow each collaborator “forks” a copy of the centralized repository. These forks represent individual remote repositories for each collaborator. Collaborators submit pull requests from their forks to the centralized repository.\n\nWhen do I need to fork?\n\n\nIf you don’t have write access and want to suggest changes, forking makes sense.\nIf you’re an active project collaborator with write access, use the branching workflow.\n\n\n\n\nEveryone has a fork of a “central” repository\nAdd commits to feature branches\nPush feature branches to individual forks\nSend pull-request from feature branch on fork to central repository\n\n\n\n\nTip #1: Always git pull before you start new work\nTip #2: Keep branch names descriptive\nTip #3: Generously use branches (but delete them when they’re merged or stale)\nTip #4: Use github command line tool (gh) to simplify your workflow\n\n\n\n\nMake a fork of https://github.com/mcsc-impact-climate/urssi-research-code and Using the forking workflow, update the script source/PrintMessage.py to instead print out your name (or something similarly personalized).\n\ndanikamacdonell@computer: ~/Git/research-code$ cd ..\ndanikamacdonell@computer: ~/Git$ git clone git@github.com:danikam/urssi-research-code.git\ndanikamacdonell@computer: ~/Git$ cd urssi-research-code\ndanikamacdonell@computer: ~/Git$ git remote add upstream git@github.com:mcsc-impact-climate/urssi-research-code.git\ndanikamacdonell@computer: ~/Git$ git checkout -b personalize-message\nAdd your new file(s), push and open a pull request\n\n\n\n\nRebasing\nRebasing lets you pull new commits from the parent branch or upstream repo (if you’re on a fork).\nFrom parent branch:\ngit fetch origin\ngit rebase origin/&lt;parent-branch&gt;\nFrom upstream forked repo:\ngit remote add upstream https://github.com/original-owner/repo.git\ngit fetch upstream\ngit rebase upstream/&lt;parent-branch&gt;\n\n\n\ntagging commits\nbranches are special labels that track a series of commits, but what if you want a special name for a particular commit (like when you released a new version of your code)? you can “tag” these\n\ngit tag -a &lt;tagname&gt; &lt;hash&gt; – useful for tagging a particular commit farther back in history\ngit tag -a &lt;tagname&gt; -m \"tag message\" – this should tag the current commit with a descriptive message\ngit push origin &lt;tagname&gt; – push a particular tag up to your remote\ngit push origin --tags – push all of your tags up to your remote\n\n\n\n\namending a commit\nOh no! I made a typo in my commit message!\ngit commit --amend is useful for both fixing commit messages and for adding in files that were supposed to be committed and werent\n\n\n\ncherry picking\nWhat if you have a commit that really belongs on a different branch? Or in development you fixed a bug that you think should be in its own PR? You can “cherry pick” that commit to a new branch.\ngit cherry-pick &lt;hash&gt;\n\n\n\nundoing changes\nReverting vs. Restoring\ngit revert &lt;commit hash&gt;\ngit restore &lt;filename&gt;\n\n\n\nstashing changes\noh no! I started making changes but I’m not on the feature branch I thought I was!\ngit stash can be used to hide the changes in your working tree and then bring them back out with git stash apply when you’re on the appropriate branch\n\n\n\nco-authoring changes\nHave you pair programmed with a friend and come up with a solution together? How do you deal with attribution?\nCo-authored-by: NAME &lt;EMAIL&gt; can add multiple authors to a commit.\n\n\n\n\nGitHub Issues help you share code issues or feature requests with collaborators\nDo you need to version control large files? git lfs and git annex are tools designed to help with this\nHow to undo almost anything with git link\nRemove sensitive data (like private keys) from a repository link\n\n\n\n\nChoose one of the following:\n\nIf you brought a project to work on: open an issue on your repository for something you’d like to improve that’s a beginner friendly issue. Describe the issue thoroughly. Then, working in groups at your tables, have a partner fork your project and submit a pull request fixing that issue. Do not merge the pull request today.\nMake a feature branch on your project and add a simple new feature to your project (could even just be some new info in the README). Submit a pull request on your project using that branch. Do not merge the pull request today."
  },
  {
    "objectID": "collaboration.html#lesson-objectives",
    "href": "collaboration.html#lesson-objectives",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Review git commands\nDescribe individual and collaborative workflows with git\nIntroduce git commands for collaborative workflows\nDemo of collaborative workflows in practice\nSee additional useful git tips/tricks"
  },
  {
    "objectID": "collaboration.html#acknowledgements",
    "href": "collaboration.html#acknowledgements",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "This material is heavily influenced by the previous works of Madicken Munk, Karthik Ram and James Howison from the previous summer and winter schools.\nOther helpful/fun resources for git\nhttps://git-school.github.io/visualizing-git/ https://pcottle.github.io/learnGitBranching/?NODEMO https://allisonhorst.com/git-github https://jvns.ca/blog/2023/11/23/branches-intuition-reality/ https://git-scm.com/docs https://swcarpentry.github.io/git-novice/"
  },
  {
    "objectID": "collaboration.html#workflows-with-git-an-individual-workflow-without-a-remote",
    "href": "collaboration.html#workflows-with-git-an-individual-workflow-without-a-remote",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "commit, commit, commit …..\ndanikamacdonell@computer: ~/Git$ mkdir research-code ; cd research-code\ndanikamacdonell@computer: ~/Git/research-code$ git init\nInitialized empty Git repository in /Users/danikamacdonell/Git/research-code/.git/\ndanikamacdonell@computer: ~/Git/research-code$ git branch -M main\ndanikamacdonell@computer: ~/Git/research-code$ touch README.md ; open README.md\ndanikamacdonell@computer: ~/Git/research-code$ git add README.md\ndanikamacdonell@computer: ~/Git/research-code$ git commit -m 'add README with code description'\n[main (root-commit) 49c9e77] add README with code description\n 1 file changed, 0 insertions(+), 0 deletions(-)\n     create mode 100644 README.md\ndanikamacdonell@computer: ~/Git/research-code$ git log\nAuthor: Danika MacDonell &lt;danikamacdonell@computer&gt;\n    Add a README with code description"
  },
  {
    "objectID": "collaboration.html#an-individual-workflow-with-a-remote",
    "href": "collaboration.html#an-individual-workflow-with-a-remote",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "commit push, commit commit push, commit push …..\ndanikamacdonell@computer: ~/Git/research-code$ git remote add origin git@github.com:danikam/research-code.git\ndanikamacdonell@computer: ~/Git/research-code$ git push -u origin main\nEnumerating objects: 3, done.\n[...]\nTo github.com:danikam/research-code.git\n * [new branch]      main -&gt; main\nbranch 'main' set up to track 'origin/main'.\nWith your code on a remote (like GitHub, GitLab, or an internal server for your lab), your work is easily accessed by peers!\n💡GitLab and other Git platforms will have slightly different interfaces and features from GitHub, but the basic actions are generally pretty similar."
  },
  {
    "objectID": "collaboration.html#centralized-workflow",
    "href": "collaboration.html#centralized-workflow",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "All members work on the same repository\ngit pull before starting work\nEveryone commits to main\ngit push\nIf there is no merge conflict, 🙌\nOtherwise fix merge conflict, then push"
  },
  {
    "objectID": "collaboration.html#feature-branching-workflow",
    "href": "collaboration.html#feature-branching-workflow",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Members work on the same repository but use individual branches to do feature development"
  },
  {
    "objectID": "collaboration.html#section",
    "href": "collaboration.html#section",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Create and switch to a branch\nAdd commits\nPush feature branch to GitHub\nStart a pull request\nDiscuss, add more commits, merge"
  },
  {
    "objectID": "collaboration.html#section-1",
    "href": "collaboration.html#section-1",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Some important commands for this workflow:\n\ngit branch\ngit checkout -b &lt;branchname&gt;\ngit push -u origin &lt;branchname&gt;\n\n\n.. add some more commits, then git push and open a pull request"
  },
  {
    "objectID": "collaboration.html#pull-requests",
    "href": "collaboration.html#pull-requests",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Pull requests are an excellent tool for fostering code review. If you’re using Github for team projects,you should be using these extensively."
  },
  {
    "objectID": "collaboration.html#pull-request-best-practices",
    "href": "collaboration.html#pull-request-best-practices",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Try to make frequent, targeted pull requests that add a specific feature or set of features\n\n✅ “Adds a new click feature for area layers in the geospatial mapping tool”\n❌ “Adds the last 3 years of my thesis work”\n\nItemize each major addition.\n\n\nA good practice is for someone else to merge your code into main, after being approved by at least one colleague. Sometimes a reviewer may not have merge rights; in these cases the requirement may be an approving review must be given before the feature is merged."
  },
  {
    "objectID": "collaboration.html#pull-request-tip",
    "href": "collaboration.html#pull-request-tip",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Using the github interface, you can change the target of a pull request. The default is to the main branch, but it could be another feature branch. This can be used if you want to help develop a feature branch outside of main with a collaborator.\n⛔️ Never send a large pull request without notice 🙅"
  },
  {
    "objectID": "collaboration.html#demo-update-summerschool-july2024-link-to-issue",
    "href": "collaboration.html#demo-update-summerschool-july2024-link-to-issue",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "[...]: ~/Git/research-code$ cd ../summerschool-July2024\n[...]: ~/Git/summerschool-July2024$ git checkout -b update-git-lesson\n[...]: ~/Git/summerschool-July2024$ open README.md\n[...]: ~/Git/summerschool-July2024$ git add README.md\n[...]: ~/Git/summerschool-July2024$ git commit -m \"Updating the Git/GitHub lesson.\"\n[...]: ~/Git/summerschool-July2024$ git push -u origin add-git-lesson\nClose the issue!"
  },
  {
    "objectID": "collaboration.html#practice",
    "href": "collaboration.html#practice",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "cd ../research-code\nUsing the feature branching workflow:\n\nUse at least two commits to:\n\nCreate a python script in the source directory called PrintMessage.py that prints a simple message.\nAdd a new section to the README to document the new script.\n\nMake a pull request!"
  },
  {
    "objectID": "collaboration.html#forking-workflow",
    "href": "collaboration.html#forking-workflow",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "In this workflow each collaborator “forks” a copy of the centralized repository. These forks represent individual remote repositories for each collaborator. Collaborators submit pull requests from their forks to the centralized repository.\n\nWhen do I need to fork?\n\n\nIf you don’t have write access and want to suggest changes, forking makes sense.\nIf you’re an active project collaborator with write access, use the branching workflow."
  },
  {
    "objectID": "collaboration.html#forking-workflow-guidelines",
    "href": "collaboration.html#forking-workflow-guidelines",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Everyone has a fork of a “central” repository\nAdd commits to feature branches\nPush feature branches to individual forks\nSend pull-request from feature branch on fork to central repository"
  },
  {
    "objectID": "collaboration.html#extra-tips",
    "href": "collaboration.html#extra-tips",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Tip #1: Always git pull before you start new work\nTip #2: Keep branch names descriptive\nTip #3: Generously use branches (but delete them when they’re merged or stale)\nTip #4: Use github command line tool (gh) to simplify your workflow"
  },
  {
    "objectID": "collaboration.html#practice-1",
    "href": "collaboration.html#practice-1",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Make a fork of https://github.com/mcsc-impact-climate/urssi-research-code and Using the forking workflow, update the script source/PrintMessage.py to instead print out your name (or something similarly personalized).\n\ndanikamacdonell@computer: ~/Git/research-code$ cd ..\ndanikamacdonell@computer: ~/Git$ git clone git@github.com:danikam/urssi-research-code.git\ndanikamacdonell@computer: ~/Git$ cd urssi-research-code\ndanikamacdonell@computer: ~/Git$ git remote add upstream git@github.com:mcsc-impact-climate/urssi-research-code.git\ndanikamacdonell@computer: ~/Git$ git checkout -b personalize-message\nAdd your new file(s), push and open a pull request"
  },
  {
    "objectID": "collaboration.html#more-useful-git-commands",
    "href": "collaboration.html#more-useful-git-commands",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Rebasing\nRebasing lets you pull new commits from the parent branch or upstream repo (if you’re on a fork).\nFrom parent branch:\ngit fetch origin\ngit rebase origin/&lt;parent-branch&gt;\nFrom upstream forked repo:\ngit remote add upstream https://github.com/original-owner/repo.git\ngit fetch upstream\ngit rebase upstream/&lt;parent-branch&gt;"
  },
  {
    "objectID": "collaboration.html#section-2",
    "href": "collaboration.html#section-2",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "tagging commits\nbranches are special labels that track a series of commits, but what if you want a special name for a particular commit (like when you released a new version of your code)? you can “tag” these\n\ngit tag -a &lt;tagname&gt; &lt;hash&gt; – useful for tagging a particular commit farther back in history\ngit tag -a &lt;tagname&gt; -m \"tag message\" – this should tag the current commit with a descriptive message\ngit push origin &lt;tagname&gt; – push a particular tag up to your remote\ngit push origin --tags – push all of your tags up to your remote"
  },
  {
    "objectID": "collaboration.html#section-3",
    "href": "collaboration.html#section-3",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "amending a commit\nOh no! I made a typo in my commit message!\ngit commit --amend is useful for both fixing commit messages and for adding in files that were supposed to be committed and werent"
  },
  {
    "objectID": "collaboration.html#section-4",
    "href": "collaboration.html#section-4",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "cherry picking\nWhat if you have a commit that really belongs on a different branch? Or in development you fixed a bug that you think should be in its own PR? You can “cherry pick” that commit to a new branch.\ngit cherry-pick &lt;hash&gt;"
  },
  {
    "objectID": "collaboration.html#section-5",
    "href": "collaboration.html#section-5",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "undoing changes\nReverting vs. Restoring\ngit revert &lt;commit hash&gt;\ngit restore &lt;filename&gt;"
  },
  {
    "objectID": "collaboration.html#section-6",
    "href": "collaboration.html#section-6",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "stashing changes\noh no! I started making changes but I’m not on the feature branch I thought I was!\ngit stash can be used to hide the changes in your working tree and then bring them back out with git stash apply when you’re on the appropriate branch"
  },
  {
    "objectID": "collaboration.html#section-7",
    "href": "collaboration.html#section-7",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "co-authoring changes\nHave you pair programmed with a friend and come up with a solution together? How do you deal with attribution?\nCo-authored-by: NAME &lt;EMAIL&gt; can add multiple authors to a commit."
  },
  {
    "objectID": "collaboration.html#more-resources",
    "href": "collaboration.html#more-resources",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "GitHub Issues help you share code issues or feature requests with collaborators\nDo you need to version control large files? git lfs and git annex are tools designed to help with this\nHow to undo almost anything with git link\nRemove sensitive data (like private keys) from a repository link"
  },
  {
    "objectID": "collaboration.html#exercises",
    "href": "collaboration.html#exercises",
    "title": "Collaboration with Git and Github",
    "section": "",
    "text": "Choose one of the following:\n\nIf you brought a project to work on: open an issue on your repository for something you’d like to improve that’s a beginner friendly issue. Describe the issue thoroughly. Then, working in groups at your tables, have a partner fork your project and submit a pull request fixing that issue. Do not merge the pull request today.\nMake a feature branch on your project and add a simple new feature to your project (could even just be some new info in the README). Submit a pull request on your project using that branch. Do not merge the pull request today."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Research Software and Open Science",
    "section": "",
    "text": "Welcome to the URSSI Summer School on Research Software and Open Science",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "package_structure.html",
    "href": "package_structure.html",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "The previous versions of this module!\nPython packaging 101 tutorial from pyOpenSci: https://www.pyopensci.org/python-package-guide/tutorials/intro.html#python-packaging-101\nPython Packages: https://py-pkgs.org/\nScientific Python packaging guide: https://learn.scientific-python.org/development/tutorials/packaging/\nPython Packaging User Guide: https://packaging.python.org/en/latest/\n\n\n\n\nFirst, let’s define module\nhttps://docs.python.org/3/glossary.html#term-module\n\nModule: An object that serves an organizational unit of python code. Modules have a namespace containing arbitrary python objects. Modules are loaded into Python by the process of importing\n\n\n\n\nDeconstructing that definition:\n\nWhen I write import modulename I am loading a module\n\nBut we also talk about “importing a package”!\nThis seems to imply a package is a kind of module\n\n\n\n\nThe module can contain “arbitrary Python objects”\n\nThat could include other modules!\nIt’s almost like we need a special name for a “module that can contain other modules”!\n\n\n\n\nWhen I load the module, its name gets added to the namespace\n\nnamespace: a collection of currently defined names and the objects they reference\nSo now I can use the module name to access things inside of it with dot notation, like another module that contains a function: numpy.random.default_rng\n\n\n\n\n\n\nThe standard library\n\nPython code\nCompiled C code\n\nA local file that ends in .py\n\n(confusingly, also called a “module”)\n\nThird-party libraries that you pip install or conda install\n\ni.e., packages\n\nA local package (we’re getting to this)\n\n\n\n\nOk, now that we spent all that time defining module, we can finally define package\n“A Python module which can contain submodules or recursively, subpackages.”\nhttps://docs.python.org/3/glossary.html#term-package\n\n\n\nTwo main usages:\nhttps://packaging.python.org/en/latest/discussions/distribution-package-vs-import-package/\n\n\n\nThis is the one we already talked about\nThe thing you get when you write import packagename in your code\nWe’re going to show you how to make one of these first\n\n\n\nThe actual artifact that gets downloaded off the internet and stored on your computer somewhere\nlike when you run pip install package\nWe need to learn how to make one of these too!\n\n\n\n\n\n\nTwo common cases for research code:\n\nCode that goes with a research article\n\nmainly used to reproduce the results\nAKA a (computational) project or a research compendium\n\nA generalized tool or library that other researchers can use\n\n\n\n\n\nYou have multiple scripts that use the same function\nSo you want to be able to import that function\nIt’s sufficient for you to make an “import package” you use in scripts (e.g., in a Jupyter notebook)\n\n\n\nThis kind of package does not necessarily need all the infrastructure you will learn about in this workshop\n\nsuch as: its own rendered website with documentation\n\nIf someone uses the code for your paper, they will get a copy of the code and set it up so they can import the same way; they don’t expect to pip install paper\n\n\nFor more on projects and research compendia in general, see\n\n“Good enough practices in scientific computing”\n“How repro-packs can save your future self”\nTuring Way guide: https://book.the-turing-way.org/reproducible-research/compendia\nKarthik’s talk: https://github.com/karthik/rstudio2019\n\n\n\n\nThis is what we’re here (mostly) to learn about!\nThis is when we want to make a “distribution package” too!\n\nYou want people to be able to pip install awesometool\n\n\n\n\n\n\n\nThe simplest possible Python package\n\nA directory with a single file in it named __init__.py\n\nThe file can be empty\n\nThe __init__.py file tells Python that “this directory is a package\n\n\n\n\n\nThis is enough for me to be able to import the package\nas long as I’m in the right directory\n\nThe same is true for any module:\n(by which we mean a file that ends in .py)\nI can import it if I’m in the right directory\n\n\n\nThis is just because of how Python’s import system works:\n“First check in the current working directory if there’s a .py file or a directory with an __init__.py that has the name we’re importing”\n\n\nHow do I make it so I can\n\npip install simple\nthen import simple without being in the right directory?\n\n\nNote that this the code I have locally, we aren’t talking about distribution packages yet!\n\n\nHow do I make it so I can pip install simple and then import simple without being in the right directory?\nWe need one more file:\na pyproject.toml file\n\n\n\nThis is the bare minimum pyproject.toml file for our simple module\n\n\n\n\n\n\n“Tom’s Obvious Minimal Language”: https://toml.io/en/\n\n“A [configuration] file format for humans”\n\nUsed in other ecosystems\nNice because parsers map to native type\n\n\n\n\n\n\n\n\n\n\n\nthe spec: https://toml.io/en/v1.0.0\n\n\n\nNow just\n\nnavigate to the directory where your module lives\nactivate your virtual environment\ntype pip install .\nnow you can import it!\n\n\n\n\n\nScenario: Samspon is a computational dog scientist.\nSampson has a set of functions they are using across all their projects, so they wrap them up in a package, dogpy\n\n\n\n\n\n\nwww.rexspecs.com/blogs/news/sampson-the-lab-dog-tests-the-boundaries-of-science\n\n\nSampson’s project dogpy has the following:\n\nA src directory (for “source code”)\nThe package itself inside src, a directory named dogpy\nA pyproject.toml file\n\n\nWhat’s different here?\n\n\n\n\n\n\n\n\n\nSo you don’t accidentally import the local package when you want to run tests on the distribution package\nAesthetics: it looks better to have “src”, “docs”, “tests”\n\n\n\n\n\nWe have the dogpy dir\nIt contains one module (by which I mean a .py file): bark.py\nIt also contains another directory! The elusive sub-package. Namely, fetch.\nThe fetch sub-package contains two other modules: ball.py and bone.py\n\n\n\n\n\nIt initializes your module\nYou import modules, functions, etc., here\nso that your users can get what they need from your package’s namespace\n\n\n\n\n\n\nShort version: “flat is better than nested”\n\nYour users want to write package.function, not package.subpackage.subsubpackage.subsubsubpackage.function\nBut having one level of sub-packages can help with readability\nMost scientific Python packages have a set of sub-packages, each containing functions:\n\nnumpy.random.default_rng\nsklearn.model_selection.test_train_split\n\nYour package’s code ≠ your package’s namespace! You control the namespace with imports!\n\nLong version:\n\nhttps://benhoyt.com/writings/python-api-design/\nhttp://blog.nicholdav.info/four-tips-structuring-research-python/\n\n\n\n\n\n\n\n\nNow we need a distribution package.\nWe also need to define some more terms so that the rest of this make sense.\n\n\n\n\nIt used to be the case that all distributions were built with a setup.py file\nThere was only one tool that did this: setuptools\nNow: pure Python projects don’t need a setup.py file It’s better\n\n\nThe long version:\nhttps://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html\n\n\n\n\nTo move away from setup.py and setuptools, PEP 517 introduced the idea of “front-ends” and “back-ends”\nhttps://peps.python.org/pep-0517/\nMostly you shouldn’t have to think about this.\nBut in your pyproject.toml file you will specify a “build backend”.\nThat’s the tool that knows how to take your “source tree” and make a distribution package.\n\n\n\n“Build backends” (always) make two types of distribution packages:\na source distribution (“sdist”), and wheels\nhttps://packaging.python.org/en/latest/discussions/package-formats/\n\n\n“Sdist”\n\nLiterally your project in a compressed archive (.tar.gz)\npip uses this as a fallback if it can’t find a wheel\nDownstream package managers use the sdist to provide their own distributions, e.g. conda, homebrew\n\nWheel\n\nCan be platform specific (e.g., Windows 64 bit)\nMatters most for packages with compiled extensions\n\n\n\n\n\nTo-do list:\n\nAdd metadata to our pyproject.toml file\n\nBuild backend\nThe metadata that will show up on PyPI\n\nBuild your distribution package\nPublish the distribution package to PyPI\n\n\n\n\n“I have to write this pyproject.toml file by hand, make and virtual environments, and I don’t even know how much work it will take to build a distribution package yet…”\nGood news!\nThere are packaging tools that will do a lot of this work for you!\n\n\n\nThe not so good news: there are many different tools\nhttps://pradyunsg.me/blog/2023/01/21/thoughts-on-python-packaging/\nHere’s two options:\n\nLightweight: flit– https://flit.pypa.io/en/stable/\nSwiss army knife: hatch – https://hatch.pypa.io/\n\n\n\n\nTo build our distribution package, we need a build system.\nWe declare this in a build-system table.\n\n\n\n\n\n\nGood explainer in flit docs:\nhttps://flit.pypa.io/en/latest/ pyproject_toml.html#new-style-metadata\n\n\n\n\n\n\n\n\nYou should know about SPEC0, that specifies what versions of Python the core scientific packages work with: https://scientific-python.org/specs/spec-0000/\nUsually you don’t want to put upper bounds (&gt;3.6, &lt;4.0) on Python or your dependencies: https://iscinumpy.dev/post/bound-version-constraints/\n\n\n\n\nMost packaging tools have some sort of build command\n\n\n\n\nMost packaging tools have some sort of publish command\n\n\n\n\n\n\n\nInfrastructure:\nAll the other stuff besides code that makes it easier for\n\nyou to develop and maintain your package\nothers to use your package, give you feedback, and contribute\n\n\n\nREADME\nLICENSE\nCode of conduct\nCHANGELOG\ndocs\ntests\nissue tracker\ncontinuous integration\n\n\n\n\n\n\n\nOften the first thing people see\nGitHub shows this by default -www.makeareadme.com/\n\n\n\n\n\n\nThings you want in your README:\n\nPackage name\nBrief description that makes sense to a broad audience\nVisuals! 1 picture = 1k words\nInstallation instructions\nUsage\nHow to contribute\nCitation information\n\n\n\n\nYou are giving other people permission to use your code\n\nhttps://choosealicense.com/\nMIT and BSD are common for open source scientific software\nMore on this later!\n\n\n\n\n\nEstablishes expectations for behavior\nHelps create inclusive community\nhttps://opensource.guide/code-of-conduct/\nHighly suggest looking at other scientific Python projects: https://docs.scipy.org/doc/scipy/dev/conduct/ code_of_conduct.html#endnotes\n\n\n\n\nHuman-readable record of changes to your project\nhttps://keepachangelog.com/en/1.1.0/\n\n\n\n\n\n\n\n\n\n\n\nTo be discussed in later modules",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#acknowledgements",
    "href": "package_structure.html#acknowledgements",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "The previous versions of this module!\nPython packaging 101 tutorial from pyOpenSci: https://www.pyopensci.org/python-package-guide/tutorials/intro.html#python-packaging-101\nPython Packages: https://py-pkgs.org/\nScientific Python packaging guide: https://learn.scientific-python.org/development/tutorials/packaging/\nPython Packaging User Guide: https://packaging.python.org/en/latest/",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#what-is-a-python-package",
    "href": "package_structure.html#what-is-a-python-package",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "First, let’s define module\nhttps://docs.python.org/3/glossary.html#term-module\n\nModule: An object that serves an organizational unit of python code. Modules have a namespace containing arbitrary python objects. Modules are loaded into Python by the process of importing",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#section",
    "href": "package_structure.html#section",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Deconstructing that definition:\n\nWhen I write import modulename I am loading a module\n\nBut we also talk about “importing a package”!\nThis seems to imply a package is a kind of module\n\n\n\n\nThe module can contain “arbitrary Python objects”\n\nThat could include other modules!\nIt’s almost like we need a special name for a “module that can contain other modules”!\n\n\n\n\nWhen I load the module, its name gets added to the namespace\n\nnamespace: a collection of currently defined names and the objects they reference\nSo now I can use the module name to access things inside of it with dot notation, like another module that contains a function: numpy.random.default_rng",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#where-do-modules-come-from",
    "href": "package_structure.html#where-do-modules-come-from",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "The standard library\n\nPython code\nCompiled C code\n\nA local file that ends in .py\n\n(confusingly, also called a “module”)\n\nThird-party libraries that you pip install or conda install\n\ni.e., packages\n\nA local package (we’re getting to this)",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#what-is-a-python-package-1",
    "href": "package_structure.html#what-is-a-python-package-1",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Ok, now that we spent all that time defining module, we can finally define package\n“A Python module which can contain submodules or recursively, subpackages.”\nhttps://docs.python.org/3/glossary.html#term-package",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#package-can-have-multiple-meanings",
    "href": "package_structure.html#package-can-have-multiple-meanings",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Two main usages:\nhttps://packaging.python.org/en/latest/discussions/distribution-package-vs-import-package/",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#two-types-of-packages-import-package",
    "href": "package_structure.html#two-types-of-packages-import-package",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "This is the one we already talked about\nThe thing you get when you write import packagename in your code\nWe’re going to show you how to make one of these first",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#two-types-of-packages-distribution-package",
    "href": "package_structure.html#two-types-of-packages-distribution-package",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "The actual artifact that gets downloaded off the internet and stored on your computer somewhere\nlike when you run pip install package\nWe need to learn how to make one of these too!",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#when-should-i-turn-my-code-into-a-package",
    "href": "package_structure.html#when-should-i-turn-my-code-into-a-package",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Two common cases for research code:\n\nCode that goes with a research article\n\nmainly used to reproduce the results\nAKA a (computational) project or a research compendium\n\nA generalized tool or library that other researchers can use",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#packaging-code-for-a-paper",
    "href": "package_structure.html#packaging-code-for-a-paper",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "You have multiple scripts that use the same function\nSo you want to be able to import that function\nIt’s sufficient for you to make an “import package” you use in scripts (e.g., in a Jupyter notebook)\n\n\n\nThis kind of package does not necessarily need all the infrastructure you will learn about in this workshop\n\nsuch as: its own rendered website with documentation\n\nIf someone uses the code for your paper, they will get a copy of the code and set it up so they can import the same way; they don’t expect to pip install paper\n\n\nFor more on projects and research compendia in general, see\n\n“Good enough practices in scientific computing”\n“How repro-packs can save your future self”\nTuring Way guide: https://book.the-turing-way.org/reproducible-research/compendia\nKarthik’s talk: https://github.com/karthik/rstudio2019",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#to-share-a-generalized-tool",
    "href": "package_structure.html#to-share-a-generalized-tool",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "This is what we’re here (mostly) to learn about!\nThis is when we want to make a “distribution package” too!\n\nYou want people to be able to pip install awesometool",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#the-structure-of-a-python-package",
    "href": "package_structure.html#the-structure-of-a-python-package",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "The simplest possible Python package\n\nA directory with a single file in it named __init__.py\n\nThe file can be empty\n\nThe __init__.py file tells Python that “this directory is a package",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#how-can-i-import-my-own-code",
    "href": "package_structure.html#how-can-i-import-my-own-code",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "This is enough for me to be able to import the package\nas long as I’m in the right directory\n\nThe same is true for any module:\n(by which we mean a file that ends in .py)\nI can import it if I’m in the right directory\n\n\n\nThis is just because of how Python’s import system works:\n“First check in the current working directory if there’s a .py file or a directory with an __init__.py that has the name we’re importing”\n\n\nHow do I make it so I can\n\npip install simple\nthen import simple without being in the right directory?\n\n\nNote that this the code I have locally, we aren’t talking about distribution packages yet!\n\n\nHow do I make it so I can pip install simple and then import simple without being in the right directory?\nWe need one more file:\na pyproject.toml file",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#how-do-i-make-it-so-i-can-import-a-module",
    "href": "package_structure.html#how-do-i-make-it-so-i-can-import-a-module",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "This is the bare minimum pyproject.toml file for our simple module",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#what-is-a-toml-file",
    "href": "package_structure.html#what-is-a-toml-file",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "“Tom’s Obvious Minimal Language”: https://toml.io/en/\n\n“A [configuration] file format for humans”\n\nUsed in other ecosystems\nNice because parsers map to native type",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#anatomy-of-a-toml-file",
    "href": "package_structure.html#anatomy-of-a-toml-file",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "the spec: https://toml.io/en/v1.0.0",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#ok-i-have-a-pyproject.toml-file-now-what",
    "href": "package_structure.html#ok-i-have-a-pyproject.toml-file-now-what",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Now just\n\nnavigate to the directory where your module lives\nactivate your virtual environment\ntype pip install .\nnow you can import it!",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#a-slightly-more-complicated-python-package",
    "href": "package_structure.html#a-slightly-more-complicated-python-package",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Scenario: Samspon is a computational dog scientist.\nSampson has a set of functions they are using across all their projects, so they wrap them up in a package, dogpy\n\n\n\n\n\n\nwww.rexspecs.com/blogs/news/sampson-the-lab-dog-tests-the-boundaries-of-science\n\n\nSampson’s project dogpy has the following:\n\nA src directory (for “source code”)\nThe package itself inside src, a directory named dogpy\nA pyproject.toml file\n\n\nWhat’s different here?",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#why-src",
    "href": "package_structure.html#why-src",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "So you don’t accidentally import the local package when you want to run tests on the distribution package\nAesthetics: it looks better to have “src”, “docs”, “tests”",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#the-package-itself",
    "href": "package_structure.html#the-package-itself",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "We have the dogpy dir\nIt contains one module (by which I mean a .py file): bark.py\nIt also contains another directory! The elusive sub-package. Namely, fetch.\nThe fetch sub-package contains two other modules: ball.py and bone.py",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#why-__init__.py-anyways",
    "href": "package_structure.html#why-__init__.py-anyways",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "It initializes your module\nYou import modules, functions, etc., here\nso that your users can get what they need from your package’s namespace",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#how-should-i-structure-my-python-package",
    "href": "package_structure.html#how-should-i-structure-my-python-package",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Short version: “flat is better than nested”\n\nYour users want to write package.function, not package.subpackage.subsubpackage.subsubsubpackage.function\nBut having one level of sub-packages can help with readability\nMost scientific Python packages have a set of sub-packages, each containing functions:\n\nnumpy.random.default_rng\nsklearn.model_selection.test_train_split\n\nYour package’s code ≠ your package’s namespace! You control the namespace with imports!\n\nLong version:\n\nhttps://benhoyt.com/writings/python-api-design/\nhttp://blog.nicholdav.info/four-tips-structuring-research-python/",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#how-do-i-publish-my-package",
    "href": "package_structure.html#how-do-i-publish-my-package",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Now we need a distribution package.\nWe also need to define some more terms so that the rest of this make sense.",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#what-about-setup.py",
    "href": "package_structure.html#what-about-setup.py",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "It used to be the case that all distributions were built with a setup.py file\nThere was only one tool that did this: setuptools\nNow: pure Python projects don’t need a setup.py file It’s better\n\n\nThe long version:\nhttps://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#distribution-packages-frontends-and-backends",
    "href": "package_structure.html#distribution-packages-frontends-and-backends",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "To move away from setup.py and setuptools, PEP 517 introduced the idea of “front-ends” and “back-ends”\nhttps://peps.python.org/pep-0517/\nMostly you shouldn’t have to think about this.\nBut in your pyproject.toml file you will specify a “build backend”.\nThat’s the tool that knows how to take your “source tree” and make a distribution package.",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#distribution-packages-formats",
    "href": "package_structure.html#distribution-packages-formats",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "“Build backends” (always) make two types of distribution packages:\na source distribution (“sdist”), and wheels\nhttps://packaging.python.org/en/latest/discussions/package-formats/\n\n\n“Sdist”\n\nLiterally your project in a compressed archive (.tar.gz)\npip uses this as a fallback if it can’t find a wheel\nDownstream package managers use the sdist to provide their own distributions, e.g. conda, homebrew\n\nWheel\n\nCan be platform specific (e.g., Windows 64 bit)\nMatters most for packages with compiled extensions",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#how-do-i-publish-my-package-1",
    "href": "package_structure.html#how-do-i-publish-my-package-1",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "To-do list:\n\nAdd metadata to our pyproject.toml file\n\nBuild backend\nThe metadata that will show up on PyPI\n\nBuild your distribution package\nPublish the distribution package to PyPI",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#python-packaging-feels-like-a-lot-of-work",
    "href": "package_structure.html#python-packaging-feels-like-a-lot-of-work",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "“I have to write this pyproject.toml file by hand, make and virtual environments, and I don’t even know how much work it will take to build a distribution package yet…”\nGood news!\nThere are packaging tools that will do a lot of this work for you!",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#python-packaging-feels-like-a-lot-of-work-1",
    "href": "package_structure.html#python-packaging-feels-like-a-lot-of-work-1",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "The not so good news: there are many different tools\nhttps://pradyunsg.me/blog/2023/01/21/thoughts-on-python-packaging/\nHere’s two options:\n\nLightweight: flit– https://flit.pypa.io/en/stable/\nSwiss army knife: hatch – https://hatch.pypa.io/",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#pyproject.toml-metadata-build-system",
    "href": "package_structure.html#pyproject.toml-metadata-build-system",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "To build our distribution package, we need a build system.\nWe declare this in a build-system table.",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#pyproject.toml-project-metadata",
    "href": "package_structure.html#pyproject.toml-project-metadata",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Good explainer in flit docs:\nhttps://flit.pypa.io/en/latest/ pyproject_toml.html#new-style-metadata",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#aside-python-requires-and-dependencies",
    "href": "package_structure.html#aside-python-requires-and-dependencies",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "You should know about SPEC0, that specifies what versions of Python the core scientific packages work with: https://scientific-python.org/specs/spec-0000/\nUsually you don’t want to put upper bounds (&gt;3.6, &lt;4.0) on Python or your dependencies: https://iscinumpy.dev/post/bound-version-constraints/",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#building-distribution-packages",
    "href": "package_structure.html#building-distribution-packages",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Most packaging tools have some sort of build command",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#publishing-to-pypi",
    "href": "package_structure.html#publishing-to-pypi",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Most packaging tools have some sort of publish command",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#what-else-do-i-need-besides-code",
    "href": "package_structure.html#what-else-do-i-need-besides-code",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Infrastructure:\nAll the other stuff besides code that makes it easier for\n\nyou to develop and maintain your package\nothers to use your package, give you feedback, and contribute\n\n\n\nREADME\nLICENSE\nCode of conduct\nCHANGELOG\ndocs\ntests\nissue tracker\ncontinuous integration",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#readme",
    "href": "package_structure.html#readme",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Often the first thing people see\nGitHub shows this by default -www.makeareadme.com/\n\n\n\n\n\n\nThings you want in your README:\n\nPackage name\nBrief description that makes sense to a broad audience\nVisuals! 1 picture = 1k words\nInstallation instructions\nUsage\nHow to contribute\nCitation information",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#license",
    "href": "package_structure.html#license",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "You are giving other people permission to use your code\n\nhttps://choosealicense.com/\nMIT and BSD are common for open source scientific software\nMore on this later!",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#code-of-conduct",
    "href": "package_structure.html#code-of-conduct",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Establishes expectations for behavior\nHelps create inclusive community\nhttps://opensource.guide/code-of-conduct/\nHighly suggest looking at other scientific Python projects: https://docs.scipy.org/doc/scipy/dev/conduct/ code_of_conduct.html#endnotes",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#changelog",
    "href": "package_structure.html#changelog",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Human-readable record of changes to your project\nhttps://keepachangelog.com/en/1.1.0/",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure.html#docs-tests-etc.",
    "href": "package_structure.html#docs-tests-etc.",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "To be discussed in later modules",
    "crumbs": [
      "(re)introducing Python packaging"
    ]
  },
  {
    "objectID": "package_structure-revealjs.html#who-am-i",
    "href": "package_structure-revealjs.html#who-am-i",
    "title": "(re)introducing Python packaging",
    "section": "Who am I?",
    "text": "Who am I?\n\nPhD: neuro + behavior, post-doc: cognition\nopen source scientific software dev: http://www.vocalpy.org/\ntrained Carpentries instructor\npyOpenSci (2018-present; Editor in Chief - ~2022-2024)\nparticipant in URSSI 2019 Winter School!\nChair, SciPy conference (2020-present)\nActive in US Research Software Engineer Association"
  },
  {
    "objectID": "package_structure-revealjs.html#acknowledgements",
    "href": "package_structure-revealjs.html#acknowledgements",
    "title": "(re)introducing Python packaging",
    "section": "Acknowledgements",
    "text": "Acknowledgements\n\nThe previous versions of this module!\nPython packaging 101 tutorial from pyOpenSci: https://www.pyopensci.org/python-package-guide/tutorials/intro.html#python-packaging-101\nPython Packages: https://py-pkgs.org/\nScientific Python packaging guide: https://learn.scientific-python.org/development/tutorials/packaging/\nPython Packaging User Guide: https://packaging.python.org/en/latest/"
  },
  {
    "objectID": "package_structure-revealjs.html#outline-questions",
    "href": "package_structure-revealjs.html#outline-questions",
    "title": "(re)introducing Python packaging",
    "section": "Outline / Questions",
    "text": "Outline / Questions\n(The answers come later)\n\nWhat is a Python package?\nWhy would I make a Python package?\nHow do I turn my code into a Python package that I can import?\nHow do I publish my Python package so others can pip install it?\nWhat do I need to develop and maintain a Python package, besides code?"
  },
  {
    "objectID": "package_structure-revealjs.html#what-is-a-python-package",
    "href": "package_structure-revealjs.html#what-is-a-python-package",
    "title": "(re)introducing Python packaging",
    "section": "What is a Python package?",
    "text": "What is a Python package?\nFirst, let’s define module\nhttps://docs.python.org/3/glossary.html#term-module\n\nModule: An object that serves an organizational unit of python code. Modules have a namespace containing arbitrary python objects. Modules are loaded into Python by the process of importing"
  },
  {
    "objectID": "package_structure-revealjs.html#section",
    "href": "package_structure-revealjs.html#section",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Deconstructing that definition:\n\nWhen I write import modulename I am loading a module\n\nBut we also talk about “importing a package”!\nThis seems to imply a package is a kind of module"
  },
  {
    "objectID": "package_structure-revealjs.html#aside-why-does-python-have-modules",
    "href": "package_structure-revealjs.html#aside-why-does-python-have-modules",
    "title": "(re)introducing Python packaging",
    "section": "Aside: why does Python have modules?",
    "text": "Aside: why does Python have modules?\nBecause it’s good for your code to be modular.\n\nImage credit: https://realpython.com/python-modules-packages/"
  },
  {
    "objectID": "package_structure-revealjs.html#where-do-modules-come-from",
    "href": "package_structure-revealjs.html#where-do-modules-come-from",
    "title": "(re)introducing Python packaging",
    "section": "Where do modules come from?",
    "text": "Where do modules come from?\n\nThe standard library\n\nPython code\nCompiled C code\n\nA local file that ends in .py\n\n(confusingly, also called a “module”)\n\nThird-party libraries that you pip install or conda install\n\ni.e., packages\n\nA local package (we’re getting to this)"
  },
  {
    "objectID": "package_structure-revealjs.html#what-is-a-python-package-1",
    "href": "package_structure-revealjs.html#what-is-a-python-package-1",
    "title": "(re)introducing Python packaging",
    "section": "What is a Python package?",
    "text": "What is a Python package?\nOk, now that we spent all that time defining module, we can finally define package\n“A Python module which can contain submodules or recursively, subpackages.”\nhttps://docs.python.org/3/glossary.html#term-package"
  },
  {
    "objectID": "package_structure-revealjs.html#package-can-have-multiple-meanings",
    "href": "package_structure-revealjs.html#package-can-have-multiple-meanings",
    "title": "(re)introducing Python packaging",
    "section": "“Package” can have multiple meanings!",
    "text": "“Package” can have multiple meanings!\nTwo main usages:\nhttps://packaging.python.org/en/latest/discussions/distribution-package-vs-import-package/"
  },
  {
    "objectID": "package_structure-revealjs.html#two-types-of-packages-import-package",
    "href": "package_structure-revealjs.html#two-types-of-packages-import-package",
    "title": "(re)introducing Python packaging",
    "section": "Two types of packages: import package",
    "text": "Two types of packages: import package\nThis is the one we already talked about\nThe thing you get when you write import packagename in your code\nWe’re going to show you how to make one of these first"
  },
  {
    "objectID": "package_structure-revealjs.html#two-types-of-packages-distribution-package",
    "href": "package_structure-revealjs.html#two-types-of-packages-distribution-package",
    "title": "(re)introducing Python packaging",
    "section": "Two types of packages: distribution package",
    "text": "Two types of packages: distribution package\nThe actual artifact that gets downloaded off the internet and stored on your computer somewhere\nlike when you run pip install package\nWe need to learn how to make one of these too!"
  },
  {
    "objectID": "package_structure-revealjs.html#why-would-i-make-a-python-package",
    "href": "package_structure-revealjs.html#why-would-i-make-a-python-package",
    "title": "(re)introducing Python packaging",
    "section": "Why would I make a Python package?",
    "text": "Why would I make a Python package?"
  },
  {
    "objectID": "package_structure-revealjs.html#section-1",
    "href": "package_structure-revealjs.html#section-1",
    "title": "(re)introducing Python packaging",
    "section": "",
    "text": "Fame, glory\n$$$\nPor amor al arte"
  },
  {
    "objectID": "package_structure-revealjs.html#when-should-i-turn-my-code-into-a-package",
    "href": "package_structure-revealjs.html#when-should-i-turn-my-code-into-a-package",
    "title": "(re)introducing Python packaging",
    "section": "When should I turn my code into a package?",
    "text": "When should I turn my code into a package?\nTwo common cases for research code:\n\nCode that goes with a research article\n\nmainly used to reproduce the results\nAKA a (computational) project or a research compendium\n\nA generalized tool or library that other researchers can use"
  },
  {
    "objectID": "package_structure-revealjs.html#packaging-code-for-a-paper",
    "href": "package_structure-revealjs.html#packaging-code-for-a-paper",
    "title": "(re)introducing Python packaging",
    "section": "Packaging code for a paper",
    "text": "Packaging code for a paper\n\nYou have multiple scripts that use the same function\nSo you want to be able to import that function\nIt’s sufficient for you to make an “import package” you use in scripts (e.g., in a Jupyter notebook)"
  },
  {
    "objectID": "package_structure-revealjs.html#to-share-a-generalized-tool",
    "href": "package_structure-revealjs.html#to-share-a-generalized-tool",
    "title": "(re)introducing Python packaging",
    "section": "To share a generalized tool",
    "text": "To share a generalized tool\nThis is what we’re here (mostly) to learn about!\nThis is when we want to make a “distribution package” too!\n\nYou want people to be able to pip install awesometool"
  },
  {
    "objectID": "package_structure-revealjs.html#how-do-i-turn-my-code-into-a-python-package-i-can-import",
    "href": "package_structure-revealjs.html#how-do-i-turn-my-code-into-a-python-package-i-can-import",
    "title": "(re)introducing Python packaging",
    "section": "How do I turn my code into a Python package I can import?",
    "text": "How do I turn my code into a Python package I can import?"
  },
  {
    "objectID": "package_structure-revealjs.html#the-structure-of-a-python-package",
    "href": "package_structure-revealjs.html#the-structure-of-a-python-package",
    "title": "(re)introducing Python packaging",
    "section": "The structure of a Python package",
    "text": "The structure of a Python package\nThe simplest possible Python package\n\nA directory with a single file in it named __init__.py\n\nThe file can be empty\n\nThe __init__.py file tells Python that “this directory is a package"
  },
  {
    "objectID": "package_structure-revealjs.html#how-can-i-import-my-own-code",
    "href": "package_structure-revealjs.html#how-can-i-import-my-own-code",
    "title": "(re)introducing Python packaging",
    "section": "How can I import my own code?",
    "text": "How can I import my own code?\nThis is enough for me to be able to import the package\nas long as I’m in the right directory\n\nThe same is true for any module:\n(by which we mean a file that ends in .py)\nI can import it if I’m in the right directory"
  },
  {
    "objectID": "package_structure-revealjs.html#how-do-i-make-it-so-i-can-import-a-module",
    "href": "package_structure-revealjs.html#how-do-i-make-it-so-i-can-import-a-module",
    "title": "(re)introducing Python packaging",
    "section": "How do I make it so I can import a module?",
    "text": "How do I make it so I can import a module?\nThis is the bare minimum pyproject.toml file for our simple module"
  },
  {
    "objectID": "package_structure-revealjs.html#what-is-a-toml-file",
    "href": "package_structure-revealjs.html#what-is-a-toml-file",
    "title": "(re)introducing Python packaging",
    "section": "What is a TOML file?",
    "text": "What is a TOML file?\n\n\n“Tom’s Obvious Minimal Language”: https://toml.io/en/\n\n“A [configuration] file format for humans”\n\nUsed in other ecosystems\nNice because parsers map to native type"
  },
  {
    "objectID": "package_structure-revealjs.html#anatomy-of-a-toml-file",
    "href": "package_structure-revealjs.html#anatomy-of-a-toml-file",
    "title": "(re)introducing Python packaging",
    "section": "Anatomy of a TOML file",
    "text": "Anatomy of a TOML file\n\n\n\nthe spec: https://toml.io/en/v1.0.0"
  },
  {
    "objectID": "package_structure-revealjs.html#ok-i-have-a-pyproject.toml-file-now-what",
    "href": "package_structure-revealjs.html#ok-i-have-a-pyproject.toml-file-now-what",
    "title": "(re)introducing Python packaging",
    "section": "Ok, I have a pyproject.toml file, now what?",
    "text": "Ok, I have a pyproject.toml file, now what?\nNow just\n\nnavigate to the directory where your module lives\nactivate your virtual environment\ntype pip install .\nnow you can import it!"
  },
  {
    "objectID": "package_structure-revealjs.html#a-slightly-more-complicated-python-package",
    "href": "package_structure-revealjs.html#a-slightly-more-complicated-python-package",
    "title": "(re)introducing Python packaging",
    "section": "A (slightly) more complicated Python package",
    "text": "A (slightly) more complicated Python package\n\nScenario: Samspon is a computational dog scientist.\nSampson has a set of functions they are using across all their projects, so they wrap them up in a package, dogpy\n\n\n\nwww.rexspecs.com/blogs/news/sampson-the-lab-dog-tests-the-boundaries-of-science"
  },
  {
    "objectID": "package_structure-revealjs.html#why-src",
    "href": "package_structure-revealjs.html#why-src",
    "title": "(re)introducing Python packaging",
    "section": "Why src?",
    "text": "Why src?\n\nSo you don’t accidentally import the local package when you want to run tests on the distribution package\nAesthetics: it looks better to have “src”, “docs”, “tests”"
  },
  {
    "objectID": "package_structure-revealjs.html#the-package-itself",
    "href": "package_structure-revealjs.html#the-package-itself",
    "title": "(re)introducing Python packaging",
    "section": "The package itself",
    "text": "The package itself\n\nWe have the dogpy dir\nIt contains one module (by which I mean a .py file): bark.py\nIt also contains another directory! The elusive sub-package. Namely, fetch.\nThe fetch sub-package contains two other modules: ball.py and bone.py"
  },
  {
    "objectID": "package_structure-revealjs.html#why-__init__.py-anyways",
    "href": "package_structure-revealjs.html#why-__init__.py-anyways",
    "title": "(re)introducing Python packaging",
    "section": "Why __init__.py anyways?",
    "text": "Why __init__.py anyways?\n\nIt initializes your module\nYou import modules, functions, etc., here\nso that your users can get what they need from your package’s namespace"
  },
  {
    "objectID": "package_structure-revealjs.html#how-should-i-structure-my-python-package",
    "href": "package_structure-revealjs.html#how-should-i-structure-my-python-package",
    "title": "(re)introducing Python packaging",
    "section": "How should I structure my Python package?",
    "text": "How should I structure my Python package?\n\nShort version: “flat is better than nested”\n\nYour users want to write package.function, not package.subpackage.subsubpackage.subsubsubpackage.function\nBut having one level of sub-packages can help with readability\nMost scientific Python packages have a set of sub-packages, each containing functions:\n\nnumpy.random.default_rng\nsklearn.model_selection.test_train_split\n\nYour package’s code ≠ your package’s namespace! You control the namespace with imports!\n\nLong version:\n\nhttps://benhoyt.com/writings/python-api-design/\nhttp://blog.nicholdav.info/four-tips-structuring-research-python/"
  },
  {
    "objectID": "package_structure-revealjs.html#how-do-i-publish-my-package-so-others-can-pip-install-it",
    "href": "package_structure-revealjs.html#how-do-i-publish-my-package-so-others-can-pip-install-it",
    "title": "(re)introducing Python packaging",
    "section": "How do I publish my package so others can pip install it?",
    "text": "How do I publish my package so others can pip install it?"
  },
  {
    "objectID": "package_structure-revealjs.html#how-do-i-publish-my-package",
    "href": "package_structure-revealjs.html#how-do-i-publish-my-package",
    "title": "(re)introducing Python packaging",
    "section": "How do I publish my package?",
    "text": "How do I publish my package?\nNow we need a distribution package.\nWe also need to define some more terms so that the rest of this make sense."
  },
  {
    "objectID": "package_structure-revealjs.html#what-about-setup.py",
    "href": "package_structure-revealjs.html#what-about-setup.py",
    "title": "(re)introducing Python packaging",
    "section": "What about setup.py?",
    "text": "What about setup.py?\n\nIt used to be the case that all distributions were built with a setup.py file\nThere was only one tool that did this: setuptools\nNow: pure Python projects don’t need a setup.py file It’s better\n\n\nThe long version:\nhttps://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html"
  },
  {
    "objectID": "package_structure-revealjs.html#distribution-packages-frontends-and-backends",
    "href": "package_structure-revealjs.html#distribution-packages-frontends-and-backends",
    "title": "(re)introducing Python packaging",
    "section": "Distribution packages: frontends and backends",
    "text": "Distribution packages: frontends and backends\nTo move away from setup.py and setuptools, PEP 517 introduced the idea of “front-ends” and “back-ends”\nhttps://peps.python.org/pep-0517/\nMostly you shouldn’t have to think about this.\nBut in your pyproject.toml file you will specify a “build backend”.\nThat’s the tool that knows how to take your “source tree” and make a distribution package."
  },
  {
    "objectID": "package_structure-revealjs.html#distribution-packages-formats",
    "href": "package_structure-revealjs.html#distribution-packages-formats",
    "title": "(re)introducing Python packaging",
    "section": "Distribution packages: formats",
    "text": "Distribution packages: formats\n“Build backends” (always) make two types of distribution packages:\na source distribution (“sdist”), and wheels\nhttps://packaging.python.org/en/latest/discussions/package-formats/"
  },
  {
    "objectID": "package_structure-revealjs.html#how-do-i-publish-my-package-1",
    "href": "package_structure-revealjs.html#how-do-i-publish-my-package-1",
    "title": "(re)introducing Python packaging",
    "section": "How do I publish my package?",
    "text": "How do I publish my package?\nTo-do list:\n\nAdd metadata to our pyproject.toml file\n\nBuild backend\nThe metadata that will show up on PyPI\n\nBuild your distribution package\nPublish the distribution package to PyPI"
  },
  {
    "objectID": "package_structure-revealjs.html#python-packaging-feels-like-a-lot-of-work",
    "href": "package_structure-revealjs.html#python-packaging-feels-like-a-lot-of-work",
    "title": "(re)introducing Python packaging",
    "section": "Python packaging feels like a lot of work!",
    "text": "Python packaging feels like a lot of work!\n“I have to write this pyproject.toml file by hand, make and virtual environments, and I don’t even know how much work it will take to build a distribution package yet…”\nGood news!\nThere are packaging tools that will do a lot of this work for you!"
  },
  {
    "objectID": "package_structure-revealjs.html#python-packaging-feels-like-a-lot-of-work-1",
    "href": "package_structure-revealjs.html#python-packaging-feels-like-a-lot-of-work-1",
    "title": "(re)introducing Python packaging",
    "section": "Python packaging feels like a lot of work!",
    "text": "Python packaging feels like a lot of work!\nThe not so good news: there are many different tools\nhttps://pradyunsg.me/blog/2023/01/21/thoughts-on-python-packaging/\nHere’s two options:\n\nLightweight: flit– https://flit.pypa.io/en/stable/\nSwiss army knife: hatch – https://hatch.pypa.io/"
  },
  {
    "objectID": "package_structure-revealjs.html#pyproject.toml-metadata-build-system",
    "href": "package_structure-revealjs.html#pyproject.toml-metadata-build-system",
    "title": "(re)introducing Python packaging",
    "section": "pyproject.toml metadata: [build-system]",
    "text": "pyproject.toml metadata: [build-system]\nTo build our distribution package, we need a build system.\nWe declare this in a build-system table."
  },
  {
    "objectID": "package_structure-revealjs.html#pyproject.toml-project-metadata",
    "href": "package_structure-revealjs.html#pyproject.toml-project-metadata",
    "title": "(re)introducing Python packaging",
    "section": "pyproject.toml project metadata",
    "text": "pyproject.toml project metadata\n\n\nGood explainer in flit docs:\nhttps://flit.pypa.io/en/latest/ pyproject_toml.html#new-style-metadata"
  },
  {
    "objectID": "package_structure-revealjs.html#aside-python-requires-and-dependencies",
    "href": "package_structure-revealjs.html#aside-python-requires-and-dependencies",
    "title": "(re)introducing Python packaging",
    "section": "Aside: python-requires and dependencies",
    "text": "Aside: python-requires and dependencies\n\nYou should know about SPEC0, that specifies what versions of Python the core scientific packages work with: https://scientific-python.org/specs/spec-0000/\nUsually you don’t want to put upper bounds (&gt;3.6, &lt;4.0) on Python or your dependencies: https://iscinumpy.dev/post/bound-version-constraints/"
  },
  {
    "objectID": "package_structure-revealjs.html#building-distribution-packages",
    "href": "package_structure-revealjs.html#building-distribution-packages",
    "title": "(re)introducing Python packaging",
    "section": "Building distribution packages",
    "text": "Building distribution packages\nMost packaging tools have some sort of build command"
  },
  {
    "objectID": "package_structure-revealjs.html#publishing-to-pypi",
    "href": "package_structure-revealjs.html#publishing-to-pypi",
    "title": "(re)introducing Python packaging",
    "section": "Publishing to PyPI",
    "text": "Publishing to PyPI\nMost packaging tools have some sort of publish command"
  },
  {
    "objectID": "package_structure-revealjs.html#what-do-i-need-to-develop-and-maintain-a-python-package-besides-code",
    "href": "package_structure-revealjs.html#what-do-i-need-to-develop-and-maintain-a-python-package-besides-code",
    "title": "(re)introducing Python packaging",
    "section": "What do I need to develop and maintain a Python package, besides code?",
    "text": "What do I need to develop and maintain a Python package, besides code?"
  },
  {
    "objectID": "package_structure-revealjs.html#what-else-do-i-need-besides-code",
    "href": "package_structure-revealjs.html#what-else-do-i-need-besides-code",
    "title": "(re)introducing Python packaging",
    "section": "What else do I need besides code?",
    "text": "What else do I need besides code?\nInfrastructure:\nAll the other stuff besides code that makes it easier for\n\nyou to develop and maintain your package\nothers to use your package, give you feedback, and contribute"
  },
  {
    "objectID": "package_structure-revealjs.html#readme",
    "href": "package_structure-revealjs.html#readme",
    "title": "(re)introducing Python packaging",
    "section": "README",
    "text": "README\n\n\n\nOften the first thing people see\nGitHub shows this by default -www.makeareadme.com/"
  },
  {
    "objectID": "package_structure-revealjs.html#license",
    "href": "package_structure-revealjs.html#license",
    "title": "(re)introducing Python packaging",
    "section": "LICENSE",
    "text": "LICENSE\nYou are giving other people permission to use your code\n\nhttps://choosealicense.com/\nMIT and BSD are common for open source scientific software\nMore on this later!"
  },
  {
    "objectID": "package_structure-revealjs.html#code-of-conduct",
    "href": "package_structure-revealjs.html#code-of-conduct",
    "title": "(re)introducing Python packaging",
    "section": "Code of conduct",
    "text": "Code of conduct\n\nEstablishes expectations for behavior\nHelps create inclusive community\nhttps://opensource.guide/code-of-conduct/\nHighly suggest looking at other scientific Python projects: https://docs.scipy.org/doc/scipy/dev/conduct/ code_of_conduct.html#endnotes"
  },
  {
    "objectID": "package_structure-revealjs.html#changelog",
    "href": "package_structure-revealjs.html#changelog",
    "title": "(re)introducing Python packaging",
    "section": "CHANGELOG",
    "text": "CHANGELOG\nHuman-readable record of changes to your project\nhttps://keepachangelog.com/en/1.1.0/"
  },
  {
    "objectID": "package_structure-revealjs.html#issue-tracker",
    "href": "package_structure-revealjs.html#issue-tracker",
    "title": "(re)introducing Python packaging",
    "section": "Issue tracker",
    "text": "Issue tracker"
  },
  {
    "objectID": "package_structure-revealjs.html#continuous-integration",
    "href": "package_structure-revealjs.html#continuous-integration",
    "title": "(re)introducing Python packaging",
    "section": "Continuous integration",
    "text": "Continuous integration"
  },
  {
    "objectID": "package_structure-revealjs.html#docs-tests-etc.",
    "href": "package_structure-revealjs.html#docs-tests-etc.",
    "title": "(re)introducing Python packaging",
    "section": "Docs, tests, etc.,",
    "text": "Docs, tests, etc.,\nTo be discussed in later modules"
  },
  {
    "objectID": "package_structure-revealjs.html#python-packaging-questions-comments",
    "href": "package_structure-revealjs.html#python-packaging-questions-comments",
    "title": "(re)introducing Python packaging",
    "section": "Python packaging: Questions & Comments",
    "text": "Python packaging: Questions & Comments"
  },
  {
    "objectID": "documentation.html",
    "href": "documentation.html",
    "title": "Documentation",
    "section": "",
    "text": "Professor Carole Goble in “Better Software, Better Research”:\n\nOne of my favorite #overlyhonestmethods tweets (a hashtag for lab scientists) is Ian Holmes’s “You can download our code from the URL supplied. Good luck downloading the only postdoc who can get it to run, though.”\n\n\n\n\n\nThe value and extent of your work is clearer if it can be understood by colleagues.\nDocumentation provides provenance for your scientific process, for your colleagues and yourself.\nDocumentation demonstrates your skill and professionalism.\n\n\n\n\n\nDocumentation pays for itself with the time it saves in the long run.\nDocumentation requires little effort beyond writing the software itself.\n\n\n\n\n\nTheory manuals\nUser and developer guides\nCode comments\nSelf-documenting code\nGenerated API documentation\n\n\n\n\n\nREADME: sits in top-level directory and contains all the necessary information for installing, getting started with, and understanding the accompanying code.\n\n\nMay be accompanied by other specific files: LICENSE, INSTALL, CITATION, ABOUT, CHANGELOG, CONTRIBUTING\n\n\n\n\nSQUIRREL, version 1.2 released on 2026-09-20\n\n# About\n\nThe Spectral Q and U Imaging Radiation Replicating Experimental Library\n(SQUIRREL) is a library for replicating radiation sources with spectral details\nand Q and U polarizations of superman bubblegum.\n\n# Installation\n\nThe SQUIRREL library relies on other libraries:\n\n- The ACORN library www.acorn.nutz\n- The TREEBRANCH database format API\n\nInstall those before installing the SQUIRREL library. To install the SQUIRREL\nlibrary:\n\n./configure\nmake --prefix=/install/path\nmake install\n...\n\n\n\nComments provide a way to insert metainformation about code intended for people, right next to the code:\ndef the_function(var):\n    \"\"\"This is a docstring, where a function definition might live\"\"\"\n    a = 1 + var # this is a simple comment\n    return a\n\n\n\nAlso possible to pollute code with unnecessary cruft:\ndef decay(index, database):\n    # first, retrieve the decay constants from the database\n    mylist = database.decay_constants()\n    # next, try to access an element of the list\n    try:\n        d = mylist[index] # gets decay constant at index in the list\n    # if the index doesn't exist\n    except IndexError:\n        # throw an informative error message\n        raise Exception(\"value not found in the list\")\n    return d\n\n\n\nCode written cleanly will have its own voice. Use intelligent naming to make most lines of code clear without comments, then use comments sparingly to help explain reasons or complicated sections:\ndef get_decay(index, database):\n    \"\"\"Returns decay constant at index in the database\"\"\"\n    lambdas = database.decay_constants()\n    try:\n        lambda_i = lambdas[index] # gets decay constant at index in the list\n    except IndexError:\n        raise Exception(\"value not found in the list\")\n    return lambda\n\n\n\n\nNaming: a class, variable, or function name should tell you why it exists, what it does, and how it is used.\n\n\nSimple functions: functions should be small to be understandable and testable; they should only do one thing.\n\n\nConsistent style: use a consistent, standardized style; e.g., select variable and function names according to the PEP8 style guide for Python.\n\n\n\n\n# packages and modules are short and lowercase\npackages\nmodules\n\n# other objects can be long\nClassesUseCamelCase\nExceptionsAreClassesToo\nfunctions_use_snake_case\nCONSTANTS_USE_ALL_CAPS\n\n# variable scope is *suggested* by style convention\n_single_leading_underscore_ # internal to module\nsingle_trailing_underscore_ # avoids conflicts with Python keywords\n__double_leading_trailing__ # these are magic, like __init__\n\n\n\n\ndocstring: comment placed immediately after a function or class definition, typically enclosed by three pairs of double quotes:\n\ndef &lt;name&gt;(&lt;args&gt;):\n    \"\"\"&lt;docstring&gt;\"\"\"\n    &lt;body&gt;\n\ndocstrings are available within Python via help() and iPython’s magic command ?, and Sphinx picks them up.\n\n\n\n\n\nMake docstrings descriptive and concise; you can explain the arguments of a function, its behavior, and how you intend it to be used.\n\ndef power(base, x):\n    \"\"\"Computes base^x. Both base and x should be integers,\n    floats, or another numeric type.\n    \"\"\"\n    return base**x",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#documentation",
    "href": "documentation.html#documentation",
    "title": "Documentation",
    "section": "",
    "text": "Professor Carole Goble in “Better Software, Better Research”:\n\nOne of my favorite #overlyhonestmethods tweets (a hashtag for lab scientists) is Ian Holmes’s “You can download our code from the URL supplied. Good luck downloading the only postdoc who can get it to run, though.”",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#value-of-documentation",
    "href": "documentation.html#value-of-documentation",
    "title": "Documentation",
    "section": "",
    "text": "The value and extent of your work is clearer if it can be understood by colleagues.\nDocumentation provides provenance for your scientific process, for your colleagues and yourself.\nDocumentation demonstrates your skill and professionalism.",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#documentation-is-easier-than-you-think.",
    "href": "documentation.html#documentation-is-easier-than-you-think.",
    "title": "Documentation",
    "section": "",
    "text": "Documentation pays for itself with the time it saves in the long run.\nDocumentation requires little effort beyond writing the software itself.",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#types-of-documentation",
    "href": "documentation.html#types-of-documentation",
    "title": "Documentation",
    "section": "",
    "text": "Theory manuals\nUser and developer guides\nCode comments\nSelf-documenting code\nGenerated API documentation",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#user-and-developer-guides",
    "href": "documentation.html#user-and-developer-guides",
    "title": "Documentation",
    "section": "",
    "text": "README: sits in top-level directory and contains all the necessary information for installing, getting started with, and understanding the accompanying code.\n\n\nMay be accompanied by other specific files: LICENSE, INSTALL, CITATION, ABOUT, CHANGELOG, CONTRIBUTING",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#readme-example",
    "href": "documentation.html#readme-example",
    "title": "Documentation",
    "section": "",
    "text": "SQUIRREL, version 1.2 released on 2026-09-20\n\n# About\n\nThe Spectral Q and U Imaging Radiation Replicating Experimental Library\n(SQUIRREL) is a library for replicating radiation sources with spectral details\nand Q and U polarizations of superman bubblegum.\n\n# Installation\n\nThe SQUIRREL library relies on other libraries:\n\n- The ACORN library www.acorn.nutz\n- The TREEBRANCH database format API\n\nInstall those before installing the SQUIRREL library. To install the SQUIRREL\nlibrary:\n\n./configure\nmake --prefix=/install/path\nmake install\n...",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#comments",
    "href": "documentation.html#comments",
    "title": "Documentation",
    "section": "",
    "text": "Comments provide a way to insert metainformation about code intended for people, right next to the code:\ndef the_function(var):\n    \"\"\"This is a docstring, where a function definition might live\"\"\"\n    a = 1 + var # this is a simple comment\n    return a",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#bad-comments",
    "href": "documentation.html#bad-comments",
    "title": "Documentation",
    "section": "",
    "text": "Also possible to pollute code with unnecessary cruft:\ndef decay(index, database):\n    # first, retrieve the decay constants from the database\n    mylist = database.decay_constants()\n    # next, try to access an element of the list\n    try:\n        d = mylist[index] # gets decay constant at index in the list\n    # if the index doesn't exist\n    except IndexError:\n        # throw an informative error message\n        raise Exception(\"value not found in the list\")\n    return d",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#useful-comments",
    "href": "documentation.html#useful-comments",
    "title": "Documentation",
    "section": "",
    "text": "Code written cleanly will have its own voice. Use intelligent naming to make most lines of code clear without comments, then use comments sparingly to help explain reasons or complicated sections:\ndef get_decay(index, database):\n    \"\"\"Returns decay constant at index in the database\"\"\"\n    lambdas = database.decay_constants()\n    try:\n        lambda_i = lambdas[index] # gets decay constant at index in the list\n    except IndexError:\n        raise Exception(\"value not found in the list\")\n    return lambda",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#self-documenting-code",
    "href": "documentation.html#self-documenting-code",
    "title": "Documentation",
    "section": "",
    "text": "Naming: a class, variable, or function name should tell you why it exists, what it does, and how it is used.\n\n\nSimple functions: functions should be small to be understandable and testable; they should only do one thing.\n\n\nConsistent style: use a consistent, standardized style; e.g., select variable and function names according to the PEP8 style guide for Python.",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#guidelines-for-naming",
    "href": "documentation.html#guidelines-for-naming",
    "title": "Documentation",
    "section": "",
    "text": "# packages and modules are short and lowercase\npackages\nmodules\n\n# other objects can be long\nClassesUseCamelCase\nExceptionsAreClassesToo\nfunctions_use_snake_case\nCONSTANTS_USE_ALL_CAPS\n\n# variable scope is *suggested* by style convention\n_single_leading_underscore_ # internal to module\nsingle_trailing_underscore_ # avoids conflicts with Python keywords\n__double_leading_trailing__ # these are magic, like __init__",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#docstrings",
    "href": "documentation.html#docstrings",
    "title": "Documentation",
    "section": "",
    "text": "docstring: comment placed immediately after a function or class definition, typically enclosed by three pairs of double quotes:\n\ndef &lt;name&gt;(&lt;args&gt;):\n    \"\"\"&lt;docstring&gt;\"\"\"\n    &lt;body&gt;\n\ndocstrings are available within Python via help() and iPython’s magic command ?, and Sphinx picks them up.",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#docstrings-more",
    "href": "documentation.html#docstrings-more",
    "title": "Documentation",
    "section": "",
    "text": "Make docstrings descriptive and concise; you can explain the arguments of a function, its behavior, and how you intend it to be used.\n\ndef power(base, x):\n    \"\"\"Computes base^x. Both base and x should be integers,\n    floats, or another numeric type.\n    \"\"\"\n    return base**x",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#numpy-style-docstrings",
    "href": "documentation.html#numpy-style-docstrings",
    "title": "Documentation",
    "section": "Numpy-style docstrings",
    "text": "Numpy-style docstrings\ndef function_with_types_in_docstring(param1, param2):\n    \"\"\"Example function with types documented in the docstring.\n\n    `PEP 484`_ type annotations are supported. If attribute, parameter, and\n    return types are annotated according to `PEP 484`_, they do not need to be\n    included in the docstring:\n\n    Parameters\n    ----------\n    param1 : int\n        The first parameter.\n    param2 : str\n        The second parameter.\n\n    Returns\n    -------\n    bool\n        True if successful, False otherwise.\n\n    .. _PEP 484:\n        https://www.python.org/dev/peps/pep-0484/\n\n    \"\"\"",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#google-style-docstrings",
    "href": "documentation.html#google-style-docstrings",
    "title": "Documentation",
    "section": "Google-style docstrings",
    "text": "Google-style docstrings\ndef function_with_types_in_docstring(param1, param2):\n    \"\"\"Example function with types documented in the docstring.\n\n    `PEP 484`_ type annotations are supported. If attribute, parameter, and\n    return types are annotated according to `PEP 484`_, they do not need to be\n    included in the docstring:\n\n    Args:\n        param1 (int): The first parameter.\n        param2 (str): The second parameter.\n\n    Returns:\n        bool: The return value. True for success, False otherwise.\n\n    .. _PEP 484:\n        https://www.python.org/dev/peps/pep-0484/\n\n    \"\"\"",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#getting-started-with-sphinx",
    "href": "documentation.html#getting-started-with-sphinx",
    "title": "Documentation",
    "section": "Getting started with Sphinx",
    "text": "Getting started with Sphinx\n\npip install sphinx myst-parser\nmkdir docs\ncd docs\nsphinx-quickstart (accept defaults if unsure; answer “yes” for question about autodoc)\nsource directory holds .rst and .md files for user guides, theory manuals, etc., separate from the autogenerated API documentation",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#add-content-for-sphinx",
    "href": "documentation.html#add-content-for-sphinx",
    "title": "Documentation",
    "section": "Add content for Sphinx",
    "text": "Add content for Sphinx\n\nIn the docs\\source directory, add an installation.md file (for example)\nAdd 'myst_parser' to extensions in conf.py\nTry building with make html\nDid sphinx find and automatically build docs for your modules? Look for .md files for each module.",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#configuration-conf.py",
    "href": "documentation.html#configuration-conf.py",
    "title": "Documentation",
    "section": "Configuration (conf.py)",
    "text": "Configuration (conf.py)\n\nAdd 'sphinx.ext.autodoc' to extensions\nIn extensions, add sphinx.ext.napoleon (for Google/NumPy-style docstring reading) and sphinx.ext.mathjax (if you want LaTeX-based equations), and sphinx.ext.intersphinx for connections to other docs\nSet napoleon_numpy_docstring and napoleon_google_docstring to True/False depending on your docstring style.\nAdd an intersphinx_mapping dict to connect to other docs",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#configuration",
    "href": "documentation.html#configuration",
    "title": "Documentation",
    "section": "Configuration",
    "text": "Configuration\n\nIn conf.py, add autodoc_default_options = {'members': True} and autoclass_content = 'class'\nFor each Python module, create a corresponding [modulename].rst file in the docs\\source directory. Add .. automodule:: [packagename].[modulename]\nIn index.rst, add [modulename] inside the toctree (table of contents)",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#intersphinx_mapping",
    "href": "documentation.html#intersphinx_mapping",
    "title": "Documentation",
    "section": "intersphinx_mapping",
    "text": "intersphinx_mapping\nintersphinx_mapping = {\n  'python': ('https://docs.python.org/3.11', None),\n  'pandas': ('http://pandas.pydata.org/pandas-docs/stable/', None),\n  'numpy': ('https://docs.scipy.org/doc/numpy/', None),\n}",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#other-sphinx-goodness",
    "href": "documentation.html#other-sphinx-goodness",
    "title": "Documentation",
    "section": "Other Sphinx goodness:",
    "text": "Other Sphinx goodness:\n\nYou can configure it to generate a LaTeX-based PDF (i.e., a single user manual)\nYou can have versioned documentation, and also simultaneously have “devel” docs for unreleased changes.",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#github-actions-to-automate-sphinx",
    "href": "documentation.html#github-actions-to-automate-sphinx",
    "title": "Documentation",
    "section": "GitHub Actions to automate Sphinx",
    "text": "GitHub Actions to automate Sphinx\nname: \"Sphinx: Render docs\"\n\non: push\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    steps:\n    - uses: actions/checkout@v4\n      with:\n        persist-credentials: false\n    - name: install depedendices\n      run : |\n        python -m pip install --upgrade pip\n        pip install .\n        pip install sphinx myst-parser\n    - name: Build HTML\n      run: |\n        cd docs\n        make html\n    - name: Upload artifacts\n      uses: actions/upload-artifact@v4\n      with:\n        name: html-docs\n        path: docs/build/html/\n    - name: Deploy\n      uses: peaceiris/actions-gh-pages@v4\n      if: github.ref == 'refs/heads/main'\n      with:\n        github_token: ${{ secrets.GITHUB_TOKEN }}\n        publish_dir: docs/build/html",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation.html#github-actions-setup",
    "href": "documentation.html#github-actions-setup",
    "title": "Documentation",
    "section": "GitHub Actions setup",
    "text": "GitHub Actions setup\n\nAdd sphinx.ext.githubpages to extensions in conf.py\nAdd a docs/requirements.txt file for any dependencies (e.g., myst-parser)\nOn GitHub, Settings -&gt; Pages -&gt; select gh-pages branch in the “Source” dropdown\n\n\nMore on Sphinx - GitHub Actions here: https://www.sphinx-doc.org/en/master/tutorial/deploying.html",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation-revealjs.html#documentation",
    "href": "documentation-revealjs.html#documentation",
    "title": "Documentation",
    "section": "Documentation",
    "text": "Documentation\nProfessor Carole Goble in “Better Software, Better Research”:\n\nOne of my favorite #overlyhonestmethods tweets (a hashtag for lab scientists) is Ian Holmes’s “You can download our code from the URL supplied. Good luck downloading the only postdoc who can get it to run, though.”"
  },
  {
    "objectID": "documentation-revealjs.html#value-of-documentation",
    "href": "documentation-revealjs.html#value-of-documentation",
    "title": "Documentation",
    "section": "Value of documentation",
    "text": "Value of documentation\n\nThe value and extent of your work is clearer if it can be understood by colleagues.\nDocumentation provides provenance for your scientific process, for your colleagues and yourself.\nDocumentation demonstrates your skill and professionalism."
  },
  {
    "objectID": "documentation-revealjs.html#documentation-is-easier-than-you-think.",
    "href": "documentation-revealjs.html#documentation-is-easier-than-you-think.",
    "title": "Documentation",
    "section": "Documentation is easier than you think.",
    "text": "Documentation is easier than you think.\n\nDocumentation pays for itself with the time it saves in the long run.\nDocumentation requires little effort beyond writing the software itself."
  },
  {
    "objectID": "documentation-revealjs.html#types-of-documentation",
    "href": "documentation-revealjs.html#types-of-documentation",
    "title": "Documentation",
    "section": "Types of documentation",
    "text": "Types of documentation\n\nTheory manuals\nUser and developer guides\nCode comments\nSelf-documenting code\nGenerated API documentation"
  },
  {
    "objectID": "documentation-revealjs.html#user-and-developer-guides",
    "href": "documentation-revealjs.html#user-and-developer-guides",
    "title": "Documentation",
    "section": "User and developer guides",
    "text": "User and developer guides\n\nREADME: sits in top-level directory and contains all the necessary information for installing, getting started with, and understanding the accompanying code.\n\n\nMay be accompanied by other specific files: LICENSE, INSTALL, CITATION, ABOUT, CHANGELOG, CONTRIBUTING"
  },
  {
    "objectID": "documentation-revealjs.html#readme-example",
    "href": "documentation-revealjs.html#readme-example",
    "title": "Documentation",
    "section": "README example",
    "text": "README example\nSQUIRREL, version 1.2 released on 2026-09-20\n\n# About\n\nThe Spectral Q and U Imaging Radiation Replicating Experimental Library\n(SQUIRREL) is a library for replicating radiation sources with spectral details\nand Q and U polarizations of superman bubblegum.\n\n# Installation\n\nThe SQUIRREL library relies on other libraries:\n\n- The ACORN library www.acorn.nutz\n- The TREEBRANCH database format API\n\nInstall those before installing the SQUIRREL library. To install the SQUIRREL\nlibrary:\n\n./configure\nmake --prefix=/install/path\nmake install\n..."
  },
  {
    "objectID": "documentation-revealjs.html#comments",
    "href": "documentation-revealjs.html#comments",
    "title": "Documentation",
    "section": "Comments",
    "text": "Comments\nComments provide a way to insert metainformation about code intended for people, right next to the code:\ndef the_function(var):\n    \"\"\"This is a docstring, where a function definition might live\"\"\"\n    a = 1 + var # this is a simple comment\n    return a"
  },
  {
    "objectID": "documentation-revealjs.html#bad-comments",
    "href": "documentation-revealjs.html#bad-comments",
    "title": "Documentation",
    "section": "Bad comments",
    "text": "Bad comments\nAlso possible to pollute code with unnecessary cruft:\ndef decay(index, database):\n    # first, retrieve the decay constants from the database\n    mylist = database.decay_constants()\n    # next, try to access an element of the list\n    try:\n        d = mylist[index] # gets decay constant at index in the list\n    # if the index doesn't exist\n    except IndexError:\n        # throw an informative error message\n        raise Exception(\"value not found in the list\")\n    return d"
  },
  {
    "objectID": "documentation-revealjs.html#useful-comments",
    "href": "documentation-revealjs.html#useful-comments",
    "title": "Documentation",
    "section": "Useful comments",
    "text": "Useful comments\nCode written cleanly will have its own voice. Use intelligent naming to make most lines of code clear without comments, then use comments sparingly to help explain reasons or complicated sections:\ndef get_decay(index, database):\n    \"\"\"Returns decay constant at index in the database\"\"\"\n    lambdas = database.decay_constants()\n    try:\n        lambda_i = lambdas[index] # gets decay constant at index in the list\n    except IndexError:\n        raise Exception(\"value not found in the list\")\n    return lambda"
  },
  {
    "objectID": "documentation-revealjs.html#self-documenting-code",
    "href": "documentation-revealjs.html#self-documenting-code",
    "title": "Documentation",
    "section": "Self-documenting code",
    "text": "Self-documenting code\n\nNaming: a class, variable, or function name should tell you why it exists, what it does, and how it is used.\n\n\nSimple functions: functions should be small to be understandable and testable; they should only do one thing.\n\n\nConsistent style: use a consistent, standardized style; e.g., select variable and function names according to the PEP8 style guide for Python."
  },
  {
    "objectID": "documentation-revealjs.html#guidelines-for-naming",
    "href": "documentation-revealjs.html#guidelines-for-naming",
    "title": "Documentation",
    "section": "Guidelines for naming",
    "text": "Guidelines for naming\n# packages and modules are short and lowercase\npackages\nmodules\n\n# other objects can be long\nClassesUseCamelCase\nExceptionsAreClassesToo\nfunctions_use_snake_case\nCONSTANTS_USE_ALL_CAPS\n\n# variable scope is *suggested* by style convention\n_single_leading_underscore_ # internal to module\nsingle_trailing_underscore_ # avoids conflicts with Python keywords\n__double_leading_trailing__ # these are magic, like __init__"
  },
  {
    "objectID": "documentation-revealjs.html#docstrings",
    "href": "documentation-revealjs.html#docstrings",
    "title": "Documentation",
    "section": "Docstrings",
    "text": "Docstrings\n\ndocstring: comment placed immediately after a function or class definition, typically enclosed by three pairs of double quotes:\n\ndef &lt;name&gt;(&lt;args&gt;):\n    \"\"\"&lt;docstring&gt;\"\"\"\n    &lt;body&gt;\n\ndocstrings are available within Python via help() and iPython’s magic command ?, and Sphinx picks them up."
  },
  {
    "objectID": "documentation-revealjs.html#docstrings-more",
    "href": "documentation-revealjs.html#docstrings-more",
    "title": "Documentation",
    "section": "Docstrings (more)",
    "text": "Docstrings (more)\n\nMake docstrings descriptive and concise; you can explain the arguments of a function, its behavior, and how you intend it to be used.\n\ndef power(base, x):\n    \"\"\"Computes base^x. Both base and x should be integers,\n    floats, or another numeric type.\n    \"\"\"\n    return base**x"
  },
  {
    "objectID": "documentation-revealjs.html#numpy-style-docstrings",
    "href": "documentation-revealjs.html#numpy-style-docstrings",
    "title": "Documentation",
    "section": "Numpy-style docstrings",
    "text": "Numpy-style docstrings\ndef function_with_types_in_docstring(param1, param2):\n    \"\"\"Example function with types documented in the docstring.\n\n    `PEP 484`_ type annotations are supported. If attribute, parameter, and\n    return types are annotated according to `PEP 484`_, they do not need to be\n    included in the docstring:\n\n    Parameters\n    ----------\n    param1 : int\n        The first parameter.\n    param2 : str\n        The second parameter.\n\n    Returns\n    -------\n    bool\n        True if successful, False otherwise.\n\n    .. _PEP 484:\n        https://www.python.org/dev/peps/pep-0484/\n\n    \"\"\""
  },
  {
    "objectID": "documentation-revealjs.html#google-style-docstrings",
    "href": "documentation-revealjs.html#google-style-docstrings",
    "title": "Documentation",
    "section": "Google-style docstrings",
    "text": "Google-style docstrings\ndef function_with_types_in_docstring(param1, param2):\n    \"\"\"Example function with types documented in the docstring.\n\n    `PEP 484`_ type annotations are supported. If attribute, parameter, and\n    return types are annotated according to `PEP 484`_, they do not need to be\n    included in the docstring:\n\n    Args:\n        param1 (int): The first parameter.\n        param2 (str): The second parameter.\n\n    Returns:\n        bool: The return value. True for success, False otherwise.\n\n    .. _PEP 484:\n        https://www.python.org/dev/peps/pep-0484/\n\n    \"\"\""
  },
  {
    "objectID": "documentation-revealjs.html#getting-started-with-sphinx",
    "href": "documentation-revealjs.html#getting-started-with-sphinx",
    "title": "Documentation",
    "section": "Getting started with Sphinx",
    "text": "Getting started with Sphinx\n\npip install sphinx myst-parser\nmkdir docs\ncd docs\nsphinx-quickstart (accept defaults if unsure; answer “yes” for question about autodoc)\nsource directory holds .rst and .md files for user guides, theory manuals, etc., separate from the autogenerated API documentation"
  },
  {
    "objectID": "documentation-revealjs.html#add-content-for-sphinx",
    "href": "documentation-revealjs.html#add-content-for-sphinx",
    "title": "Documentation",
    "section": "Add content for Sphinx",
    "text": "Add content for Sphinx\n\nIn the docs\\source directory, add an installation.md file (for example)\nAdd 'myst_parser' to extensions in conf.py\nTry building with make html\nDid sphinx find and automatically build docs for your modules? Look for .md files for each module."
  },
  {
    "objectID": "documentation-revealjs.html#configuration-conf.py",
    "href": "documentation-revealjs.html#configuration-conf.py",
    "title": "Documentation",
    "section": "Configuration (conf.py)",
    "text": "Configuration (conf.py)\n\nAdd 'sphinx.ext.autodoc' to extensions\nIn extensions, add sphinx.ext.napoleon (for Google/NumPy-style docstring reading) and sphinx.ext.mathjax (if you want LaTeX-based equations), and sphinx.ext.intersphinx for connections to other docs\nSet napoleon_numpy_docstring and napoleon_google_docstring to True/False depending on your docstring style.\nAdd an intersphinx_mapping dict to connect to other docs"
  },
  {
    "objectID": "documentation-revealjs.html#configuration",
    "href": "documentation-revealjs.html#configuration",
    "title": "Documentation",
    "section": "Configuration",
    "text": "Configuration\n\nIn conf.py, add autodoc_default_options = {'members': True} and autoclass_content = 'class'\nFor each Python module, create a corresponding [modulename].rst file in the docs\\source directory. Add .. automodule:: [packagename].[modulename]\nIn index.rst, add [modulename] inside the toctree (table of contents)"
  },
  {
    "objectID": "documentation-revealjs.html#intersphinx_mapping",
    "href": "documentation-revealjs.html#intersphinx_mapping",
    "title": "Documentation",
    "section": "intersphinx_mapping",
    "text": "intersphinx_mapping\nintersphinx_mapping = {\n  'python': ('https://docs.python.org/3.11', None),\n  'pandas': ('http://pandas.pydata.org/pandas-docs/stable/', None),\n  'numpy': ('https://docs.scipy.org/doc/numpy/', None),\n}"
  },
  {
    "objectID": "documentation-revealjs.html#other-sphinx-goodness",
    "href": "documentation-revealjs.html#other-sphinx-goodness",
    "title": "Documentation",
    "section": "Other Sphinx goodness:",
    "text": "Other Sphinx goodness:\n\nYou can configure it to generate a LaTeX-based PDF (i.e., a single user manual)\nYou can have versioned documentation, and also simultaneously have “devel” docs for unreleased changes."
  },
  {
    "objectID": "documentation-revealjs.html#github-actions-to-automate-sphinx",
    "href": "documentation-revealjs.html#github-actions-to-automate-sphinx",
    "title": "Documentation",
    "section": "GitHub Actions to automate Sphinx",
    "text": "GitHub Actions to automate Sphinx\nname: \"Sphinx: Render docs\"\n\non: push\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    steps:\n    - uses: actions/checkout@v4\n      with:\n        persist-credentials: false\n    - name: install depedendices\n      run : |\n        python -m pip install --upgrade pip\n        pip install .\n        pip install sphinx myst-parser\n    - name: Build HTML\n      run: |\n        cd docs\n        make html\n    - name: Upload artifacts\n      uses: actions/upload-artifact@v4\n      with:\n        name: html-docs\n        path: docs/build/html/\n    - name: Deploy\n      uses: peaceiris/actions-gh-pages@v4\n      if: github.ref == 'refs/heads/main'\n      with:\n        github_token: ${{ secrets.GITHUB_TOKEN }}\n        publish_dir: docs/build/html"
  },
  {
    "objectID": "documentation-revealjs.html#github-actions-setup",
    "href": "documentation-revealjs.html#github-actions-setup",
    "title": "Documentation",
    "section": "GitHub Actions setup",
    "text": "GitHub Actions setup\n\nAdd sphinx.ext.githubpages to extensions in conf.py\nAdd a docs/requirements.txt file for any dependencies (e.g., myst-parser)\nOn GitHub, Settings -&gt; Pages -&gt; select gh-pages branch in the “Source” dropdown\n\n\nMore on Sphinx - GitHub Actions here: https://www.sphinx-doc.org/en/master/tutorial/deploying.html"
  },
  {
    "objectID": "software_design.html",
    "href": "software_design.html",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Motivation\nCore Ideas\nBasic Application\nCommon Patterns\nTakeaways",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#agenda",
    "href": "software_design.html#agenda",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Motivation\nCore Ideas\nBasic Application\nCommon Patterns\nTakeaways",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#motivation",
    "href": "software_design.html#motivation",
    "title": "Software Design and Modularity",
    "section": "Motivation",
    "text": "Motivation",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section",
    "href": "software_design.html#section",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Computers do exactly what you program them to do.\n\n\nIf you aren’t getting the results you expect, look for a simpler model.",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#three-targets-for-simpler-programs",
    "href": "software_design.html#three-targets-for-simpler-programs",
    "title": "Software Design and Modularity",
    "section": "Three Targets For Simpler Programs",
    "text": "Three Targets For Simpler Programs\n\nMake software easier to understand by breaking it into pieces that can be understood separately\n\n\nMake it easier to collaborate with others by making your code understandable OR make it easier for yourself when you ultimately need to revisit your code after six months, a year, or more working on a different project.",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section-1",
    "href": "software_design.html#section-1",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Enable the ability to maintain, reuse and extend software (or bits of software)\n\n\nBy breaking software into pieces that can be understood and operate independently, we hope they are not only easier to maintain, but portable from project to project. If your research continues to build off prior work, why doesn’t your code?",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section-2",
    "href": "software_design.html#section-2",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Avoid extra work from lack of forethought towards methods of engagement with software\n\n\nLess work good 👍👍",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#core-ideas",
    "href": "software_design.html#core-ideas",
    "title": "Software Design and Modularity",
    "section": "Core Ideas",
    "text": "Core Ideas",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#core-ideas-1",
    "href": "software_design.html#core-ideas-1",
    "title": "Software Design and Modularity",
    "section": "Core Ideas",
    "text": "Core Ideas\n\nDecomposable – can be broken down into modules to reduce complexity and allow teamwork\nComposable – enable code to be reused in many places\nUnderstandable – one module can be examined, reasoned about, developed, etc. in isolation\nContinuity – a small change in the requirements should affect a small number of modules\nIsolation – an error in one module should be as contained as possible",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section-3",
    "href": "software_design.html#section-3",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Cohesion – internal consistency Generally, we want to break down our code into smaller pieces but we should have consistency in design and pattern across all of those pieces.\n\n\nFor example, how you handle errors, how you name variables, how you process data, etc. Changing your coding style from function to function can make it harder to understand and maintain your code.",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section-4",
    "href": "software_design.html#section-4",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Well designed software should try to minimize the mental effort required to reason about it.\n\n\nIf there are too complex of functions, break them out to think about and develop one at a time.",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#basic-applications",
    "href": "software_design.html#basic-applications",
    "title": "Software Design and Modularity",
    "section": "Basic Applications",
    "text": "Basic Applications",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section-5",
    "href": "software_design.html#section-5",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "You want to write a program to gather data from a number of sources (databases, web sites, etc.), all of this data has similar structure but may have slightly different formats.",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section-6",
    "href": "software_design.html#section-6",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Following our “separate code into small pieces” idea, our first thought might be to write a single function that can gather data from any our sources – at the very least, you have separated out the data gathering from the data processing.",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section-7",
    "href": "software_design.html#section-7",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "A single function separated out is already an improvement! But, if you have many sources of data, you may want to define and structure your code in a way that makes it easy to add new sources of data. In Python, one way to do this is via “AbstractBaseClasses” (ABCs).",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section-8",
    "href": "software_design.html#section-8",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Lets start with a toy example where you want to pull price data for a number of items from a number of sellers.\n\nfrom abc import ABC, abstractmethod\n\nimport pandas as pd\n\n\nclass DataSource(ABC):\n    @abstractmethod\n    def pull_data(self) -&gt; pd.DataFrame:\n        pass\n\n    @staticmethod\n    def validate_data(data: pd.DataFrame) -&gt; None:\n        # Check that all the columns we need are present\n        if any(\n            feature not in data.columns\n            for feature in [\"name\", \"description\", \"price\", \"category\"]\n        ):\n            raise ValueError(\"The dataset does not contain all the necessary columns\")\n\n        # Check that the price is non-negative\n        if (data[\"price\"] &lt; 0).any():\n            raise ValueError(\"The price cannot be negative\")\n\n        # etc. etc.\nclass AmazonDataSource(DataSource):\n    def pull_data(self) -&gt; pd.DataFrame:\n        # You likely going to pull data from their API or service\n        # keep that contained here\n        # ...\n        # before you return the data, validate it\n        DataSource.validate_data(data)\n        return data\n\n\nclass TargetDataSource(DataSource):\n    def pull_data(self) -&gt; pd.DataFrame:\n        # You likely going to pull data from their API or service\n        # keep that contained here\n        # ...\n        # before you return the data, validate it\n        DataSource.validate_data(data)\n        return data",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section-9",
    "href": "software_design.html#section-9",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Abstract Base Classes ABCs are great! They allow you to define a common interface for a group of classes. As well as enforce that the classes that inherit from the ABC implement the methods you define.\n\n\nAs with validate_data you can also attach utility functions that each sub-class may want to use to keep everything together.\n\n\nBut, there are lots of other ways to structure code and other design patterns.",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#common-patterns",
    "href": "software_design.html#common-patterns",
    "title": "Software Design and Modularity",
    "section": "Common Patterns",
    "text": "Common Patterns",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section-10",
    "href": "software_design.html#section-10",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "For the next ten minutes, with a partner, look through:\nhttps://github.com/faif/python-patterns\nThink about how any of these patterns might be useful to a problem you recently encountered.\nA first one to look at might be the factory which is very useful when trying to have a standard interface to create different objects or functions using a parameter.\nEx: you are processing a bunch of different image file formats and you need to find the appropriate file reader for each\nAs you are doing this, make note of patterns you find interesting or particularly useful and why. Or take note of patterns you have never seen before",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#takeaways",
    "href": "software_design.html#takeaways",
    "title": "Software Design and Modularity",
    "section": "Takeaways",
    "text": "Takeaways",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section-11",
    "href": "software_design.html#section-11",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Three Targets For Simpler Programs\n\nMake software easier to understand by breaking it into pieces that can be understood separately\nEnable the ability to maintain, reuse and extend software (or bits of software)\nAvoid extra work from lack of forethought towards methods of engagement with software",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section-12",
    "href": "software_design.html#section-12",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Well designed software should try to minimize the mental effort required to reason about it.\nIf there are too complex of functions, break them out to think about and develop one at a time. If there is too much coupling between functions or modules, try to reduce coupling.",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section-13",
    "href": "software_design.html#section-13",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Learn and apply coding patterns. There are many resources to look up common patterns.\nA good way to learn them is to use the example code commonly given and change, add, or remove values and see what happens.",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software_design.html#section-14",
    "href": "software_design.html#section-14",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Credit\nMuch of the content of this talk comes from:\n\nUW CSE 331 Lecture 1\nPrevious URSSI Winter School\nSoftware Design for Research Software",
    "crumbs": [
      "Software Design and Modularity"
    ]
  },
  {
    "objectID": "software-revealjs.html#agenda",
    "href": "software-revealjs.html#agenda",
    "title": "Software Design and Modularity",
    "section": "Agenda",
    "text": "Agenda\n\nMotivation\nCore Ideas\nBasic Application\nCommon Patterns\nTakeaways"
  },
  {
    "objectID": "software-revealjs.html#motivation",
    "href": "software-revealjs.html#motivation",
    "title": "Software Design and Modularity",
    "section": "Motivation",
    "text": "Motivation"
  },
  {
    "objectID": "software-revealjs.html#section",
    "href": "software-revealjs.html#section",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Computers do exactly what you program them to do.\n\n\nIf you aren’t getting the results you expect, look for a simpler model."
  },
  {
    "objectID": "software-revealjs.html#three-targets-for-simpler-programs",
    "href": "software-revealjs.html#three-targets-for-simpler-programs",
    "title": "Software Design and Modularity",
    "section": "Three Targets For Simpler Programs",
    "text": "Three Targets For Simpler Programs\n\nMake software easier to understand by breaking it into pieces that can be understood separately\n\n\nMake it easier to collaborate with others by making your code understandable OR make it easier for yourself when you ultimately need to revisit your code after six months, a year, or more working on a different project."
  },
  {
    "objectID": "software-revealjs.html#section-1",
    "href": "software-revealjs.html#section-1",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Enable the ability to maintain, reuse and extend software (or bits of software)\n\n\nBy breaking software into pieces that can be understood and operate independently, we hope they are not only easier to maintain, but portable from project to project. If your research continues to build off prior work, why doesn’t your code?"
  },
  {
    "objectID": "software-revealjs.html#section-2",
    "href": "software-revealjs.html#section-2",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Avoid extra work from lack of forethought towards methods of engagement with software\n\n\nLess work good 👍👍"
  },
  {
    "objectID": "software-revealjs.html#core-ideas",
    "href": "software-revealjs.html#core-ideas",
    "title": "Software Design and Modularity",
    "section": "Core Ideas",
    "text": "Core Ideas"
  },
  {
    "objectID": "software-revealjs.html#core-ideas-1",
    "href": "software-revealjs.html#core-ideas-1",
    "title": "Software Design and Modularity",
    "section": "Core Ideas",
    "text": "Core Ideas\n\nDecomposable – can be broken down into modules to reduce complexity and allow teamwork\nComposable – enable code to be reused in many places\nUnderstandable – one module can be examined, reasoned about, developed, etc. in isolation\nContinuity – a small change in the requirements should affect a small number of modules\nIsolation – an error in one module should be as contained as possible"
  },
  {
    "objectID": "software-revealjs.html#section-3",
    "href": "software-revealjs.html#section-3",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Cohesion – internal consistency Generally, we want to break down our code into smaller pieces but we should have consistency in design and pattern across all of those pieces.\n\n\nFor example, how you handle errors, how you name variables, how you process data, etc. Changing your coding style from function to function can make it harder to understand and maintain your code."
  },
  {
    "objectID": "software-revealjs.html#section-4",
    "href": "software-revealjs.html#section-4",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Well designed software should try to minimize the mental effort required to reason about it.\n\n\nIf there are too complex of functions, break them out to think about and develop one at a time."
  },
  {
    "objectID": "software-revealjs.html#basic-applications",
    "href": "software-revealjs.html#basic-applications",
    "title": "Software Design and Modularity",
    "section": "Basic Applications",
    "text": "Basic Applications"
  },
  {
    "objectID": "software-revealjs.html#section-5",
    "href": "software-revealjs.html#section-5",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "You want to write a program to gather data from a number of sources (databases, web sites, etc.), all of this data has similar structure but may have slightly different formats."
  },
  {
    "objectID": "software-revealjs.html#section-6",
    "href": "software-revealjs.html#section-6",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Following our “separate code into small pieces” idea, our first thought might be to write a single function that can gather data from any our sources – at the very least, you have separated out the data gathering from the data processing."
  },
  {
    "objectID": "software-revealjs.html#section-7",
    "href": "software-revealjs.html#section-7",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "A single function separated out is already an improvement! But, if you have many sources of data, you may want to define and structure your code in a way that makes it easy to add new sources of data. In Python, one way to do this is via “AbstractBaseClasses” (ABCs)."
  },
  {
    "objectID": "software-revealjs.html#section-8",
    "href": "software-revealjs.html#section-8",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Lets start with a toy example where you want to pull price data for a number of items from a number of sellers.\n\nfrom abc import ABC, abstractmethod\n\nimport pandas as pd\n\n\nclass DataSource(ABC):\n    @abstractmethod\n    def pull_data(self) -&gt; pd.DataFrame:\n        pass\n\n    @staticmethod\n    def validate_data(data: pd.DataFrame) -&gt; None:\n        # Check that all the columns we need are present\n        if any(\n            feature not in data.columns\n            for feature in [\"name\", \"description\", \"price\", \"category\"]\n        ):\n            raise ValueError(\"The dataset does not contain all the necessary columns\")\n\n        # Check that the price is non-negative\n        if (data[\"price\"] &lt; 0).any():\n            raise ValueError(\"The price cannot be negative\")\n\n        # etc. etc.\nclass AmazonDataSource(DataSource):\n    def pull_data(self) -&gt; pd.DataFrame:\n        # You likely going to pull data from their API or service\n        # keep that contained here\n        # ...\n        # before you return the data, validate it\n        DataSource.validate_data(data)\n        return data\n\n\nclass TargetDataSource(DataSource):\n    def pull_data(self) -&gt; pd.DataFrame:\n        # You likely going to pull data from their API or service\n        # keep that contained here\n        # ...\n        # before you return the data, validate it\n        DataSource.validate_data(data)\n        return data"
  },
  {
    "objectID": "software-revealjs.html#section-9",
    "href": "software-revealjs.html#section-9",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Abstract Base Classes ABCs are great! They allow you to define a common interface for a group of classes. As well as enforce that the classes that inherit from the ABC implement the methods you define.\n\n\nAs with validate_data you can also attach utility functions that each sub-class may want to use to keep everything together.\n\n\nBut, there are lots of other ways to structure code and other design patterns."
  },
  {
    "objectID": "software-revealjs.html#common-patterns",
    "href": "software-revealjs.html#common-patterns",
    "title": "Software Design and Modularity",
    "section": "Common Patterns",
    "text": "Common Patterns"
  },
  {
    "objectID": "software-revealjs.html#section-10",
    "href": "software-revealjs.html#section-10",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "For the next ten minutes, with a partner, look through:\nhttps://github.com/faif/python-patterns\nThink about how any of these patterns might be useful to a problem you recently encountered.\nA first one to look at might be the factory which is very useful when trying to have a standard interface to create different objects or functions using a parameter.\nEx: you are processing a bunch of different image file formats and you need to find the appropriate file reader for each\nAs you are doing this, make note of patterns you find interesting or particularly useful and why. Or take note of patterns you have never seen before"
  },
  {
    "objectID": "software-revealjs.html#takeaways",
    "href": "software-revealjs.html#takeaways",
    "title": "Software Design and Modularity",
    "section": "Takeaways",
    "text": "Takeaways"
  },
  {
    "objectID": "software-revealjs.html#section-11",
    "href": "software-revealjs.html#section-11",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Three Targets For Simpler Programs\n\nMake software easier to understand by breaking it into pieces that can be understood separately\nEnable the ability to maintain, reuse and extend software (or bits of software)\nAvoid extra work from lack of forethought towards methods of engagement with software"
  },
  {
    "objectID": "software-revealjs.html#section-12",
    "href": "software-revealjs.html#section-12",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Well designed software should try to minimize the mental effort required to reason about it.\nIf there are too complex of functions, break them out to think about and develop one at a time. If there is too much coupling between functions or modules, try to reduce coupling."
  },
  {
    "objectID": "software-revealjs.html#section-13",
    "href": "software-revealjs.html#section-13",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Learn and apply coding patterns. There are many resources to look up common patterns.\nA good way to learn them is to use the example code commonly given and change, add, or remove values and see what happens."
  },
  {
    "objectID": "software-revealjs.html#section-14",
    "href": "software-revealjs.html#section-14",
    "title": "Software Design and Modularity",
    "section": "",
    "text": "Credit\nMuch of the content of this talk comes from:\n\nUW CSE 331 Lecture 1\nPrevious URSSI Winter School\nSoftware Design for Research Software"
  }
]